{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osteisarcoma Label Cleaning Multiple Instance Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.stats import binom\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import random\n",
    "import openslide\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import cv2 as cv\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import os\n",
    "from os.path import basename\n",
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Basic Slide information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your WSI file\n",
    "wsi_path_1 = '/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-15 18.31.27.ndpi'\n",
    "wsi_label_path_1 = \"/export/io86/data/jhu101/OTS-23-17323 - 2023-06-15 18.31.27.ndpi.xml\"\n",
    "\n",
    "#Open the WSI file\n",
    "slide = openslide.OpenSlide(wsi_path_1)\n",
    "# print(f\"Slide Level Count:{slide.level_count}\")\n",
    "# print(f\"Slide Dimensions:{slide.dimensions}\")\n",
    "# print(f\"Slide level dimensions:{slide.level_dimensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Generate Tissue Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_Aaron(img,adjust_otsu, fill_size=50, remove_size=50):\n",
    "    # 16714505 1.21\n",
    "    # 16714503 1.25\n",
    "    #Changing the BGR Channel to Gray\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    #Setting a threhold where >threhold =255; <threhold =0. This is for denoising\n",
    "    otsu_threshold, _ = cv.threshold(gray, 0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    #Apply to our downsampling WSI\n",
    "    binary = gray<= (otsu_threshold*adjust_otsu)\n",
    "    #Don't quite understand this part? Why should we do this.\n",
    "    binary = morphology.remove_small_objects(morphology.remove_small_holes(binary, fill_size),remove_size)\n",
    "    return binary\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tissue_mask(slide_ob,unit,adjust_otsu):\n",
    "    \"\"\"\n",
    "    Generate tissue mask (downsampled) for WSI\n",
    "    - Input\n",
    "        slide_ob: slide object\n",
    "        unit: downsample scale\n",
    "        adjust_otsu: adjust the OTSU threshold\n",
    "    - Return\n",
    "        mask tissue\n",
    "    \"\"\"\n",
    "    #Get the width and height of WSI\n",
    "    width,height = slide_ob.dimensions\n",
    "    #Get the downsampling width and height of WSI\n",
    "    width_downsample, height_downsample = width//unit, height//unit\n",
    "    #Get the thumnail with respect to the down-sampling WSI \n",
    "    thumbnail = slide_ob.get_thumbnail((width_downsample,width_downsample))\n",
    "    #Using opencv to resize the thumnial. Aim to convert the image to numpy array\n",
    "    thumbnail = cv.resize(np.array(thumbnail)[:,:,:3],(width_downsample,height_downsample))\n",
    "    #Use binary to denoise our image and convert it to numpy array\n",
    "    mask_tissue = np.array(binary_Aaron(thumbnail, adjust_otsu),dtype=np.uint8) \n",
    "    return mask_tissue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate label mask\n",
    "def generate_label_mask(slide_ob, annotations, annotation_label_mapping, unit):\n",
    "    \"\"\"\n",
    "    Generate label mask (downsampled) for WSI\n",
    "    - Input\n",
    "        slide_ob: slide object\n",
    "        annotations: {'annotation_key':{'outer': [(x,y),....],'inner':[(x,y),...]}}\n",
    "        'annotation_label_mapping': {'annotation_key': int}\n",
    "        unit: downsample scale\n",
    "    - Return\n",
    "        Mask: label mask\n",
    "    \"\"\"\n",
    "    width, height = slide_ob.dimensions\n",
    "    Mask = np.zeros((int(height/unit),int(width/unit)),dtype=float)\n",
    "    for annotation_key in annotations.keys():\n",
    "        mask =  Image.new('1', (int(np.round(width/unit)),int(np.round(height/unit))))\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "        for contour in annotations[annotation_key]['outer']:\n",
    "            contour = [(i[0]/unit,i[1]/unit) for i in contour]\n",
    "            draw.polygon(contour,fill=1,outline=0)\n",
    "        for contour in annotations[annotation_key]['inner']:\n",
    "            contour = [(i[0]/unit,i[1]/unit) for i in contour]\n",
    "            draw.polygon(contour,fill=0,outline=0)\n",
    "        mask = np.array(mask)\n",
    "        Mask[mask==1] = annotation_label_mapping[annotation_key]\n",
    "    return Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adjust_otsu =1\n",
    "mask_tissue = generate_tissue_mask(slide,256,adjust_otsu)\n",
    "plt.imshow(mask_tissue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Mask Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_mask(slide_ob, annotations, annotation_label_mapping, unit):\n",
    "    \"\"\"\n",
    "    Generate label mask (downsampled) for WSI\n",
    "    - Input\n",
    "        slide_ob: slide object\n",
    "        annotations: {'annotation_key':{'outer': [(x,y),....],'inner':[(x,y),...]}}\n",
    "        'annotation_label_mapping': {'annotation_key': int}\n",
    "        unit: downsample scale\n",
    "    - Return\n",
    "        Mask: label mask\n",
    "    \"\"\"\n",
    "    #Get the width and height of our WSI\n",
    "    width, height = slide_ob.dimensions\n",
    "    #Build an empty label mask matrix for storing the labels later\n",
    "    Mask = np.zeros((int(height/unit),int(width/unit)),dtype=float)\n",
    "    #Find the labels for each classes: Viable, necrosis and stroma\n",
    "    for annotation_key in annotations.keys():\n",
    "      #Create a new image with mode 1(1-bit pixels,black and white)\n",
    "        mask =  Image.new('1', (int(np.round(width/unit)),int(np.round(height/unit))))\n",
    "        #Draw the labels for each class\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "        #Get the coordinates information for each location inside one class\n",
    "        for contour in annotations[annotation_key]['outer']:\n",
    "          #Consider the downsampling factor\n",
    "            contour = [(i[0]/unit,i[1]/unit) for i in contour]\n",
    "            #Use polygon to connect the vetex and draw the regions wrt classes\n",
    "            draw.polygon(contour,fill=1,outline=0)\n",
    "        for contour in annotations[annotation_key]['inner']:\n",
    "            contour = [(i[0]/unit,i[1]/unit) for i in contour]\n",
    "            draw.polygon(contour,fill=0,outline=0)\n",
    "        #Convert our created image into arrays(each mask representing the labels for each class)\n",
    "        mask = np.array(mask)\n",
    "        #Mapping all our class labels to one big matrix, which means the matrix will contain all the labels(In our case,1 for viable,2 for necrosis, 3 for stroma )\n",
    "        Mask[mask==1] = annotation_label_mapping[annotation_key]\n",
    "    return Mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Aaron_annotations(xml_path):\n",
    "    root = ET.parse(xml_path)\n",
    "    Annotations={'viable':{'outer':[], 'inner':[]},\n",
    "                'necrosis':{'outer':[], 'inner':[]},\n",
    "                'stroma':{'outer':[], 'inner':[]},\n",
    "                'type4':{'outer':[], 'inner':[]}}\n",
    "    for a in root.iter('Annotation'):\n",
    "        for r in a.iter('Region'):\n",
    "            Annotation = []\n",
    "            for v in r.iter('Vertex'):\n",
    "                Annotation.append((float(v.attrib['X']), float(v.attrib['Y'])))\n",
    "            if a.attrib['LineColor'] == '16711680' :\n",
    "                Annotations['viable']['outer'].append(Annotation)\n",
    "            elif a.attrib['LineColor'] == '255':\n",
    "                Annotations['necrosis']['outer'].append(Annotation)\n",
    "            elif a.attrib['LineColor'] == '65280' or a.attrib['LineColor'] == '1376057':\n",
    "                Annotations['stroma']['outer'].append(Annotation)\n",
    "            elif a.attrib['LineColor'] == '65535':\n",
    "                Annotations['type4']['outer'].append(Annotation)\n",
    "    return Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set Annotation mapping as following:\n",
    "annotation_label_mapping ={\n",
    "    'stroma':1,\n",
    "    'viable':2,\n",
    "    'necrosis':3,\n",
    "    'type4':4\n",
    "}\n",
    "#Read the annotations\n",
    "Annotations=read_Aaron_annotations(wsi_label_path_1)\n",
    "# Annotations2=read_Aaron_annotations(wsi_label_path_2)\n",
    "#Get the label Mask\n",
    "Mask = generate_label_mask(slide,Annotations,annotation_label_mapping,256)\n",
    "# Mask2 = generate_label_mask(slide2,Annotations2,annotation_label_mapping,256)\n",
    "# Mask_dic = {\"s1\":Mask,\"s2\":Mask2}\n",
    "np.sum((np.array(Mask))==2)\n",
    "# plt.imshow(Mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.stats import binom\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Dataset: Mixslide Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TSbags_random_mixpatch2(data_utils.Dataset):\n",
    "#     def __init__(self, slide_obs, masks_tissue, masks_label, level, patch_shape, length_bag_mean, num_bags, transform,mode='train'):\n",
    "#         self.slide_obs = slide_obs\n",
    "#         self.masks_tissue = masks_tissue\n",
    "#         self.masks_label = masks_label\n",
    "#         self.level = level\n",
    "#         self.patch_shape =patch_shape\n",
    "#         self.length_bag_mean = length_bag_mean\n",
    "#         self.num_bags = num_bags\n",
    "#         self.transform = transform\n",
    "#         self.Patch_list, self.Label_patch_list = self._mix_patches()\n",
    "#         self.train_bags_list,self.train_labels_list,self.val_bags_list,self.val_labels_list = self._create_bags()\n",
    "#         self.mode = mode\n",
    "\n",
    "\n",
    "#     def _mix_patches(self):\n",
    "#         # to return: [(slide_ID,row,col)]\n",
    "#         Patch_list = []\n",
    "#         Label_patch_list = []\n",
    "#         #Iterate though each slide\n",
    "#         for slide_ID in self.slide_obs.keys():\n",
    "#           #Find the tissue mask and label for each slide\n",
    "#             # print(\"\")\n",
    "#             # print(slide_ID)\n",
    "#             mask_tissue = self.masks_tissue[slide_ID]\n",
    "#             mask_label = self.masks_label[slide_ID]\n",
    "#             for label in range(len(self.num_bags)):\n",
    "#               #Find all the pixels belong to tissue and correponding class\n",
    "#                 ROW, COL = np.where((mask_tissue==1)&(mask_label==(label+1))) # mask_label=labelmask_label>3none\n",
    "#                 #print(f\"Type 4: {np.sum(mask_label==1)}\")\n",
    "\n",
    "#                 #Aggregate all the pixels belong to tissue in a long list\n",
    "#                 Patch_list.extend([(slide_ID,ROW[i],COL[i]) for i in range(len(ROW))])\n",
    "#                 #Aggregate all the labels as well\n",
    "#                 Label_patch_list.extend([label+1]*len(ROW))\n",
    "#         return Patch_list, np.array(Label_patch_list)\n",
    "\n",
    "\n",
    "#     def _create_bags(self):\n",
    "#         train_bags_list = [] #len=total number of classes. Each list inside is the patch coordinates.\n",
    "#         train_labels_list = []\n",
    "#         val_bags_list = []\n",
    "#         val_labels_list=[]\n",
    "#       #  print(self.num_bags)\n",
    "#         for label in range(len(self.num_bags)): #label=0,1,2\n",
    "#             #print(label+1)\n",
    "#           #Index where the Label_patch_list ==1 eg\n",
    "#             Indices = np.where(self.Label_patch_list==(label+1))[0] #Indices (219602,) pxiels where the patch_list label is the same as the label\n",
    "#             #print(f\"{label+1}:{len(Indices)}\")\n",
    "#             # random.shuffle(Indices)\n",
    "#             random.seed(42)\n",
    "#             shuffled_indices = Indices[:]\n",
    "#             split_idx = int(0.7*len(Indices))\n",
    "#             # Slices dataset into train and validation\n",
    "#             train_indices = shuffled_indices[:split_idx]\n",
    "#             # print(len(train_indices))\n",
    "#             val_indices = shuffled_indices[split_idx:]\n",
    "#             #Find the coordinates of each class bags respectively and append them\n",
    "#             #print(f\"val_indices: {len(train_indices)}\")\n",
    "\n",
    "#             #Train bags\n",
    "#             for bag_idx in range(self.num_bags[label]):\n",
    "#                 length_bag = binom.rvs (n=int(self.length_bag_mean*2), p=0.5) #randomly sampling bag length mean\n",
    "#                 indices = random.sample(train_indices.tolist(),length_bag) #Indices (219602,) samplesbag length \n",
    "#                 train_bags_list.append(indices)\n",
    "#                 train_labels_list.append(label)\n",
    "\n",
    "#             #Validation bags\n",
    "#             for bag_idx in range(int(0.5*self.num_bags[label])):\n",
    "#                 length_bag = binom.rvs (n=int(self.length_bag_mean*2), p=0.5) #randomly sampling bag length mean\n",
    "#                 indices = random.sample(val_indices.tolist(),length_bag) #Indices (219602,) samplesbag length \n",
    "#                 val_bags_list.append(indices)\n",
    "#                 val_labels_list.append(label)\n",
    "#         return train_bags_list,train_labels_list,val_bags_list,val_labels_list\n",
    "\n",
    "#         # return bags_list, labels_list\n",
    "    \n",
    "#     def _pack_one_bag(self,indices):\n",
    "#         Bag = []\n",
    "#         for index in indices:\n",
    "#             slide_ID, row_unit, col_unit = self.Patch_list[index]\n",
    "#             factor = self.slide_obs[slide_ID].level_downsamples[self.level]\n",
    "#             unit = int(self.slide_obs[slide_ID].dimensions[0]/self.masks_tissue[slide_ID].shape[1])\n",
    "#             upperLeft_x = int(col_unit * unit + unit/2 - self.patch_shape/2*factor) # Pick the upperleft x coordinate\n",
    "#             upperLeft_y = int(row_unit * unit + unit/2 - self.patch_shape/2*factor) # Pick the upperleft y coordinate\n",
    "#             #Find patch using read_region in open slide\n",
    "#             patch = self.slide_obs[slide_ID].read_region((upperLeft_x, upperLeft_y),self.level,(self.patch_shape,self.patch_shape))\n",
    "#             patch = Image.fromarray(np.array(patch)[:,:,:3])\n",
    "#             if self.transform is not None:\n",
    "#                 patch = self.transform(patch)\n",
    "#             Bag.append(patch) # Stack bags into one numpy array\n",
    "#         #Stack patches into bags\n",
    "#         Bag = np.stack(Bag,axis=0)\n",
    "#         return Bag\n",
    "#     def __len__(self):\n",
    "#         if self.mode == \"train\":\n",
    "#             return len(self.train_bags_list)\n",
    "#         else:\n",
    "#             return len(self.val_bags_list)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         if self.mode == \"train\":\n",
    "#             indices = self.train_bags_list[index]\n",
    "#             bag = self._pack_one_bag(indices)\n",
    "#             label = self.train_labels_list[index]\n",
    "#             return bag, label\n",
    "#         else: \n",
    "#             indices = self.val_bags_list[index]\n",
    "#             bag = self._pack_one_bag(indices)\n",
    "#             label = self.val_labels_list[index]\n",
    "#             return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSbags_random_mixpatch(data_utils.Dataset):\n",
    "    def __init__(self, slide_obs, masks_tissue, masks_label, level, patch_shape, length_bag_mean, num_bags, transform):\n",
    "        self.slide_obs = slide_obs\n",
    "        self.masks_tissue = masks_tissue\n",
    "        self.masks_label = masks_label\n",
    "        self.level = level\n",
    "        self.patch_shape =patch_shape\n",
    "        self.length_bag_mean = length_bag_mean\n",
    "        self.num_bags = num_bags\n",
    "        self.transform = transform\n",
    "        self.Patch_list, self.Label_patch_list = self._mix_patches()\n",
    "        self.bags_list, self.labels_list = self._create_bags()  \n",
    "        \n",
    "    def _mix_patches(self):\n",
    "        # to return: [(slide_ID,row,col)]\n",
    "        Patch_list = []\n",
    "        Label_patch_list = []\n",
    "        for slide_ID in self.slide_obs.keys():\n",
    "            mask_tissue = self.masks_tissue[slide_ID]\n",
    "            mask_label = self.masks_label[slide_ID]\n",
    "            for label in range(len(self.num_bags)):\n",
    "                ROW, COL = np.where((mask_tissue==1)&(mask_label==(label+1)))\n",
    "                Patch_list.extend([(slide_ID,ROW[i],COL[i]) for i in range(len(ROW))])\n",
    "                Label_patch_list.extend([label]*len(ROW))\n",
    "        return Patch_list, np.array(Label_patch_list)\n",
    "            \n",
    "    def _create_bags(self):            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for label in range(len(self.num_bags)):\n",
    "            Indices = np.where(self.Label_patch_list==label)[0]\n",
    "            for bag_idx in range(self.num_bags[label]):\n",
    "                length_bag = binom.rvs (n=int(self.length_bag_mean*2), p=0.5)\n",
    "                indices = random.sample(Indices.tolist(),length_bag)\n",
    "                bags_list.append(indices)\n",
    "                labels_list.append(label)\n",
    "        return bags_list, labels_list\n",
    "    def _pack_one_bag(self,indices):\n",
    "        Bag = []\n",
    "        for index in indices:\n",
    "            slide_ID, row_unit, col_unit = self.Patch_list[index]\n",
    "            factor = self.slide_obs[slide_ID].level_downsamples[self.level]\n",
    "            unit = int(self.slide_obs[slide_ID].dimensions[0]/self.masks_tissue[slide_ID].shape[1])\n",
    "            upperLeft_x = int(col_unit * unit + unit/2 - self.patch_shape/2*factor)\n",
    "            upperLeft_y = int(row_unit * unit + unit/2 - self.patch_shape/2*factor)\n",
    "            patch = self.slide_obs[slide_ID].read_region((upperLeft_x, upperLeft_y),self.level,(self.patch_shape,self.patch_shape))\n",
    "            patch = Image.fromarray(np.array(patch)[:,:,:3])\n",
    "            if self.transform is not None:\n",
    "                patch = self.transform(patch)\n",
    "            Bag.append(patch)\n",
    "        Bag = np.stack(Bag,axis=0)\n",
    "        return Bag  \n",
    "    def __len__(self):\n",
    "        return len(self.bags_list)  \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.bags_list[index]\n",
    "        bag = self._pack_one_bag(indices)\n",
    "        label = self.labels_list[index]\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Mix patches\n",
    "# def create_dataset_mixpatch2(slides, tissue_masks, label_masks, num_bags, level, patch_shape,length_bag_mean = 10,mode=\"train\"):\n",
    "#     \"\"\"\n",
    "#     Generate data loaders\n",
    "#     - Input\n",
    "#         slides: dictionary {'slide_ID':slide_ob}\n",
    "#         tissue_masks: dictionary {'slide_ID':array}\n",
    "#         label_masks: dictionary {'slide_ID':array}\n",
    "#         num_bags:list\n",
    "#         level:int\n",
    "#         patch_shape:int\n",
    "#     - Return\n",
    "#         Dataset\n",
    "#     \"\"\"\n",
    "#     # Training loaders\n",
    "#     Dataset = TSbags_random_mixpatch(slide_obs = slides,\n",
    "#                                             masks_tissue = tissue_masks, \n",
    "#                                             masks_label = label_masks, \n",
    "#                                             level = level, \n",
    "#                                             patch_shape = patch_shape, \n",
    "#                                             length_bag_mean = length_bag_mean, \n",
    "#                                             num_bags = num_bags, \n",
    "#                                           transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor(),\n",
    "#                                           transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),\n",
    "#                                           mode=mode)      \n",
    "#     return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix patches\n",
    "def create_dataset_mixpatch(slides, tissue_masks, label_masks, num_bags, level, patch_shape,length_bag_mean = 10):\n",
    "    \"\"\"\n",
    "    Generate data loaders\n",
    "    - Input\n",
    "        slides: dictionary {'slide_ID':slide_ob}\n",
    "        tissue_masks: dictionary {'slide_ID':array}\n",
    "        label_masks: dictionary {'slide_ID':array}\n",
    "        num_bags:list\n",
    "        level:int\n",
    "        patch_shape:int\n",
    "    - Return\n",
    "        Dataset\n",
    "    \"\"\"\n",
    "    # Training loaders\n",
    "    Dataset = TSbags_random_mixpatch(slide_obs = slides,\n",
    "                                            masks_tissue = tissue_masks, \n",
    "                                            masks_label = label_masks, \n",
    "                                            level = level, \n",
    "                                            patch_shape = patch_shape, \n",
    "                                            length_bag_mean = length_bag_mean, \n",
    "                                            num_bags = num_bags, \n",
    "                                          transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))      \n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 LC-MIL model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_modern_multi2(nn.Module):\n",
    "    def __init__(self,cnn,focal_loss=False):\n",
    "        super(Attention_modern_multi2,self).__init__()\n",
    "        #Attention Pooling input dimension\n",
    "        self.L = 1000\n",
    "        self.D = 64\n",
    "        self.K = 1 \n",
    "        self.focal_loss = focal_loss     \n",
    "        self.feature_extractor = cnn      \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K, 4)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x .squeeze(0)\n",
    "        H = self.feature_extractor(x)\n",
    "        A = self.attention(H)\n",
    "        A = torch.transpose(A,1,0)\n",
    "        #Rescale attention weights between 0 and 1\n",
    "        A = F.softmax(A,dim=1)\n",
    "        M = torch.mm(A,H)\n",
    "        Y_prob = self.classifier(M)\n",
    "        #Convert Raw logit to probability\n",
    "        Y_prob = F.softmax(Y_prob,dim=1)\n",
    "\n",
    "        return Y_prob, A\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y_prob,_ = self.forward(X)\n",
    "        #Choose the class with the max probability\n",
    "        Y_hat = torch.argmax(Y_prob[0])\n",
    "        #Calculate the classification accuracy\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().data.item()\n",
    "\n",
    "        return error, Y_hat, Y_prob\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y_prob, A = self.forward(X) # ylabel0123dataloaderlabel1\n",
    "        #print(f\"Y_prob:{Y_prob}\")\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        if not self.focal_loss:\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            #print(f\"focal_loss; label:{Y}\")\n",
    "            neg_log_likelihood = loss(Y_prob, Y)\n",
    "        else:\n",
    "            #print(f\"label:{Y}\")\n",
    "            Y_prob_target = Y_prob[0,Y.cpu().data]\n",
    "            #print(f\"else; Y_prob_target:{Y_prob_target}\")\n",
    "            if Y_prob_target.cpu().data.numpy()[0]<0.2:\n",
    "                gamma = 5\n",
    "            else:\n",
    "                gamma = 3\n",
    "            neg_log_likelihood =-1. *(1-Y_prob_target)**gamma* torch.log(Y_prob_target)\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_modern_multi(nn.Module):\n",
    "    def __init__(self,cnn,focal_loss=False):\n",
    "        super(Attention_modern_multi,self).__init__()\n",
    "        #Attention Pooling input dimension\n",
    "        self.L = 1000\n",
    "        self.L2 = 32\n",
    "        self.D = 64\n",
    "        self.K = 1\n",
    "        self.focal_loss = focal_loss\n",
    "        #Feature_extracter vgg16 with first two child weights freezed\n",
    "        self.feature_extractor = cnn\n",
    "        #Attention Pooling\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L*self.K,  self.L2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.L2,4)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x .squeeze(0)\n",
    "        H = self.feature_extractor(x)\n",
    "        A = self.attention(H)\n",
    "        A = torch.transpose(A,1,0)\n",
    "        #Rescale attention weights between 0 and 1\n",
    "        A = F.softmax(A,dim=1)\n",
    "        M = torch.mm(A,H)\n",
    "        Y_prob = self.classifier(M)\n",
    "        #Convert Raw logit to probability\n",
    "        Y_prob = F.softmax(Y_prob,dim=1)\n",
    "\n",
    "        return Y_prob, A\n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y_prob,_ = self.forward(X)\n",
    "        #Choose the class with the max probability\n",
    "        Y_hat = torch.argmax(Y_prob[0])\n",
    "        #Calculate the classification accuracy\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().data.item()\n",
    "\n",
    "        return error, Y_hat, Y_prob\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y_prob, A = self.forward(X) # ylabel0123dataloaderlabel1\n",
    "        #print(f\"Y_prob:{Y_prob}\")\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        if not self.focal_loss:\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            #print(f\"focal_loss; label:{Y}\")\n",
    "            neg_log_likelihood = loss(Y_prob, Y)\n",
    "        else:\n",
    "            #print(f\"label:{Y}\")\n",
    "            Y_prob_target = Y_prob[0,Y.cpu().data]\n",
    "            #print(f\"else; Y_prob_target:{Y_prob_target}\")\n",
    "            if Y_prob_target.cpu().data.numpy()[0]<0.2:\n",
    "                gamma = 5\n",
    "            else:\n",
    "                gamma = 3\n",
    "            neg_log_likelihood =-1. *(1-Y_prob_target)**gamma* torch.log(Y_prob_target)\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg16():\n",
    "    vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "    num_layer = 0\n",
    "    #Fine tune the fully connect layer\n",
    "    for child in vgg.children():\n",
    "        num_layer+=1\n",
    "        if num_layer < 3:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False#Freeze covolutional and pooling layer\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg16_tune():\n",
    "    vgg = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
    "    for param in vgg.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for layer_num in range(21,31):\n",
    "        for param in vgg.features[layer_num].parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # for layer_num,child in enumerate(vgg.features.children()):\n",
    "    #     for param in child.parameters():\n",
    "            # print(f'Layer {layer_num}, requires_grad: {param.requires_grad}')\n",
    "\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n",
    "# data = TSbags_random_mixpatch(slides_train,tissue_masks_train,label_masks_train, level, patch_shape,10,train_bag_len,transform)\n",
    "# n_val =len(data)\n",
    "# split_train =100\n",
    "# indices_val = random.sample(list(range(n_val)),k=100)\n",
    "# Sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "# Dataloader_val = data_utils.DataLoader(data, sampler = Sampler_val, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # device = torch.device(\"cuda:6\")\n",
    "# # torch.cuda.set_device(device)\n",
    "# model = Attention_modern_multi(load_vgg16(),True)\n",
    "# # model = model.to(device)\n",
    "# for batch_idx, (data, label) in enumerate(Dataloader_val):\n",
    "#     bag_label = label\n",
    "#     # data, bag_label = data.to(device), bag_label.to(device)\n",
    "#     data, bag_label = Variable(data), Variable(bag_label)\n",
    "#     loss, _ = model.calculate_objective(data, bag_label)\n",
    "#     print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, Dataloader_train):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (data, label) in enumerate(Dataloader_train):\n",
    "        bag_label = label\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "        loss, _ = model.calculate_objective(data, bag_label)\n",
    "        error, _, _ = model.calculate_classification_error(data, bag_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.data.cpu().numpy()[0]\n",
    "        train_error += error\n",
    "        del data\n",
    "        del bag_label\n",
    "    train_loss /= len(Dataloader_train)\n",
    "    train_error /= len(Dataloader_train)\n",
    "    return model, train_loss, 1-train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, Dataloader_val):\n",
    "    val_loss = 0.\n",
    "    val_error = 0.      \n",
    "    for batch_idx, (data, label) in enumerate(Dataloader_val):\n",
    "        bag_label = label\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data,requires_grad=False), Variable(bag_label,requires_grad=False)\n",
    "        loss, _ = model.calculate_objective(data, bag_label)\n",
    "        error, _, _ = model.calculate_classification_error(data, bag_label)\n",
    "        val_loss += loss.data.cpu().numpy()[0]\n",
    "        val_error += error\n",
    "        del data\n",
    "        del bag_label\n",
    "    val_loss /= len(Dataloader_val)\n",
    "    val_error /= len(Dataloader_val)\n",
    "    return val_loss, 1-val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, Dataloader_test):\n",
    "    test_error = 0. \n",
    "    pred_labels = []   \n",
    "    true_labels = [] \n",
    "    for batch_idx, (data, label) in enumerate(Dataloader_test):\n",
    "        bag_label = label\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data,requires_grad=False), Variable(bag_label,requires_grad=False)\n",
    "        error, pred, _ = model.calculate_classification_error(data, bag_label)\n",
    "        pred_labels.append(pred.data.cpu().item())\n",
    "        true_labels.append(bag_label.data.cpu().item())\n",
    "        test_error += error\n",
    "        if batch_idx%499 ==0:\n",
    "            print(f\"{batch_idx}th test accuracy:{1-(test_error/(batch_idx+1)):.3f}\")\n",
    "        del data\n",
    "        del bag_label\n",
    "    test_error /= len(Dataloader_test)\n",
    "    return pred_labels, true_labels,1-test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, Dataset_train, optimizer, scheduler, validation=False, Dataset_val = None):\n",
    "    wandb.watch(model, log = \"all\", log_freq = 10)\n",
    "    \n",
    "    n_train = len(Dataset_train)\n",
    "    split_train = 400\n",
    "    indices_train = random.sample(list(range(n_train)),k=n_train)\n",
    "    Train_loss = []\n",
    "    Train_accuracy = []\n",
    "    Val_loss = []\n",
    "    Val_accuracy = []\n",
    "\n",
    "    if validation:\n",
    "        n_val = len(Dataset_val)\n",
    "        indices_val = random.sample(list(range(n_val)),k=400)\n",
    "\n",
    "    for i in range(n_train//split_train):\n",
    "        print(f\"epoch: {i}\")\n",
    "        Sampler_train = torch.utils.data.sampler.SubsetRandomSampler(indices_train[i*split_train:(i+1)*split_train])\n",
    "        Dataloader_train = data_utils.DataLoader(Dataset_train, sampler = Sampler_train, batch_size = 1, shuffle = False)\n",
    "        model.cuda()\n",
    "        model, train_loss, train_accuracy = train(model, optimizer, Dataloader_train)\n",
    "        Train_loss.append(train_loss)\n",
    "        \n",
    "        Train_accuracy.append(train_accuracy)\n",
    "        scheduler.step()\n",
    "\n",
    "        #Log training metric to wandb\n",
    "        wandb.log({ \"train_loss\": train_loss, \"train_accuracy\": train_accuracy})\n",
    "\n",
    "        print(\"epoch={}/{}, train loss = {:.3f}, train_accuracy = {:.3f}\".format(i, n_train//split_train, train_loss, train_accuracy))\n",
    "        if validation:\n",
    "            Sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "            Dataloader_val = data_utils.DataLoader(Dataset_val, sampler = Sampler_val, batch_size = 1, shuffle = False)\n",
    "            val_loss, val_accuracy = val(model, Dataloader_val)\n",
    "            Val_loss.append(val_loss)\n",
    "            Val_accuracy.append(val_accuracy)\n",
    "\n",
    "            #log validation metric to wandb\n",
    "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "\n",
    "           \n",
    "            print(\"epoch={}/{}, val loss = {:.3f}, val_accuracy = {:.3f}\".format(i, n_train//split_train, val_loss, val_accuracy))\n",
    "        \n",
    "        if i%50 ==0:\n",
    "                torch.save(model.state_dict(), f\"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/exptune_mixpatch_{i}_epoch.pth\")\n",
    "        \n",
    "    torch.save(model.state_dict(), f\"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/mixpatch_final.pth\")\n",
    "    return model, Train_loss, Train_accuracy, Val_loss, Val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5A. Training Using Multiple slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 OSTU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step0\n",
    "#Read OSTU dictoinary\n",
    "with open(\"/cis/home/jhu104/osteosarcoma/OSTU/ostu.dic\", 'r') as j:\n",
    "     adjust_otsu_all1 = json.loads(j.read())\n",
    "\n",
    "#step1\n",
    "#Get basename dictionray\n",
    "data_dic = {}\n",
    "for key,value in adjust_otsu_all1.items():\n",
    "     basename = os.path.basename(key)\n",
    "     data_dic[basename] = value\n",
    "\n",
    "\n",
    "#step2\n",
    "#Read training file from zhenzhen\n",
    "split_df = pd.read_csv(\"/cis/home/jhu104/osteosarcoma/OSTU/osteosarcoma_experiment_setting.csv\")\n",
    "\n",
    "\n",
    "#step3\n",
    "#change the dictionary to df\n",
    "ostu_df = pd.DataFrame(data_dic.items())\n",
    "ostu_df.rename(columns={0: \"image_name\", 1: \"OSTU\"}, inplace=True)\n",
    "\n",
    "\n",
    "#step4\n",
    "#merge the table\n",
    "split_df=split_df.merge(ostu_df,on = [\"image_name\"])\n",
    "split_df=split_df.sort_values(by=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the label\n",
    "label_list = []\n",
    "directory = '/export/io86/data/jhu101'\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        label_list.append(filepath)\n",
    "\n",
    "\n",
    "#Find matched label\n",
    "def find_matched_label(image,label):\n",
    "    label_match = []\n",
    "    for i in range(len(image)):\n",
    "        appendix = os.path.basename(image[i])\n",
    "        appendix = appendix+\".xml\"\n",
    "        for j in range(len(label)):\n",
    "            if appendix == os.path.basename(label_list[j]):\n",
    "                label_match.append(label_list[j])\n",
    "    return label_match\n",
    "\n",
    "\n",
    "#Find all image path\n",
    "random.seed(42)\n",
    "directory = '/cis/home/jhu104/jhu101'\n",
    "datalist=[]\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        datalist.append(filepath)\n",
    "#randomly shuffle the dataset\n",
    "random.shuffle(datalist)\n",
    "\n",
    "\n",
    "#Get train,test and validation data path\n",
    "def get_data(directory):\n",
    "    base = '/cis/home/jhu104/jhu101'\n",
    "    datatrain=[]\n",
    "    for i in range(len(directory)):\n",
    "        filepath = os.path.join(base, directory[i])\n",
    "        datatrain.append(filepath)\n",
    "    return datatrain\n",
    " \n",
    "\n",
    "#Split into training,validation and test\n",
    "#train\n",
    "train_data = get_data(split_df[split_df[\"dataset\"] ==\"training\"][\"image_name\"].to_list())\n",
    "train_label = find_matched_label(train_data,label_list)\n",
    "\n",
    "#val\n",
    "val_data = get_data(split_df[split_df[\"dataset\"] ==\"validation\"][\"image_name\"].to_list())\n",
    "val_label = find_matched_label(val_data,label_list)\n",
    "\n",
    "#test\n",
    "test_data = get_data(split_df[split_df[\"dataset\"] ==\"test\"][\"image_name\"].to_list())\n",
    "test_label = find_matched_label(test_data,label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Training Slide Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find settings for slides\n",
    "def slide_setting(data,label):\n",
    "    dic = {}\n",
    "    for i in range(len(data)):\n",
    "        Annotations=read_Aaron_annotations(label[i])\n",
    "        slide = openslide.OpenSlide(data[i])\n",
    "        Mask = generate_label_mask(slide,Annotations,annotation_label_mapping,256)\n",
    "        # print(f\"\"\"{i+1}st slide: viable: {round(np.sum(np.array(Mask)==1)/20)},\n",
    "        #                         necrosis: {round(np.sum(np.array(Mask)==2)/20)}, \n",
    "        #                         stroma: {round(np.sum(np.array(Mask)==3)/20)}, type4: {round(np.sum(np.array(Mask)==4)/20)}\"\"\")\n",
    "\n",
    "        # viable = round(np.sum(np.array(Mask) == 1) / 20)\n",
    "        # necrosis = round(np.sum(np.array(Mask) == 2) / 10)\n",
    "        # stroma = round(np.sum(np.array(Mask) == 3) / 20)\n",
    "        # type4 = round(np.sum(np.array(Mask) == 4)/2 ) \n",
    "        viable = 500\n",
    "        necrosis = 500\n",
    "        stroma = 500\n",
    "        type4 = 500\n",
    "        dic[(data[i])] ={\n",
    "            'stroma': stroma,\n",
    "            'viable': viable,\n",
    "            'necrosis': necrosis,\n",
    "            'type4': type4,\n",
    "        }\n",
    "    return dic\n",
    "\n",
    "#Get the bag length\n",
    "Settings = slide_setting(train_data,train_label)\n",
    "\n",
    "#Insert the OTSU\n",
    "def insert_otsu(settingslides,adjust_otsu_type):\n",
    "    for key, adjust_otsu in zip(settingslides.keys(), adjust_otsu_type):\n",
    "        settingslides[key]['adjust_otsu'] = adjust_otsu\n",
    "    return settingslides\n",
    "\n",
    "#Get the train setting\n",
    "\n",
    "adjust_otsu_train = split_df[split_df[\"dataset\"] ==\"training\"][\"OSTU\"].to_list()\n",
    "Settings =insert_otsu(Settings,adjust_otsu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all training WSIs\n",
    "unit = 256\n",
    "level = 2 # 10x magnification\n",
    "patch_shape = 256\n",
    "annotation_label_mapping ={\n",
    "    'stroma':1,\n",
    "    'viable':2,\n",
    "    'necrosis':3,\n",
    "    'type4':4\n",
    "}\n",
    "slides_train = {}\n",
    "num_bags_train = {}\n",
    "annotations_train = {}\n",
    "tissue_masks_train = {}\n",
    "label_masks_train = {}\n",
    "for i, slide_ID in enumerate(train_data):\n",
    "    slides_train[slide_ID] = openslide.OpenSlide(slide_ID)\n",
    "    annotations_train[slide_ID] = read_Aaron_annotations(train_label[i])\n",
    "    num_bags_train[slide_ID] = [Settings[slide_ID]['stroma'],Settings[slide_ID]['viable'],Settings[slide_ID]['necrosis'],Settings[slide_ID]['type4']]    \n",
    "    tissue_masks_train[slide_ID] = generate_tissue_mask(slides_train[slide_ID],unit=unit,adjust_otsu=Settings[slide_ID]['adjust_otsu'])\n",
    "    label_masks_train[slide_ID] = generate_label_mask(slides_train[slide_ID], annotations_train[slide_ID], annotation_label_mapping, unit)\n",
    "\n",
    "#Find the train bag total length\n",
    "train_bag_len =[0,0,0,0]\n",
    "for idx,key in num_bags_train.items():\n",
    "    train_bag_len[0] += key[0] \n",
    "    train_bag_len[1] += key[1] \n",
    "    train_bag_len[2] += key[2] \n",
    "    train_bag_len[3] += key[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Validation Slide Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find settings for validation slides\n",
    "def slide_setting(data,label):\n",
    "    dic = {}\n",
    "    for i in range(len(data)):\n",
    "        Annotations=read_Aaron_annotations(label[i])\n",
    "        slide = openslide.OpenSlide(data[i])\n",
    "        Mask = generate_label_mask(slide,Annotations,annotation_label_mapping,256)\n",
    "        # print(f\"\"\"{i+1}st slide: viable: {round(np.sum(np.array(Mask)==1)/20)},\n",
    "        #                         necrosis: {round(np.sum(np.array(Mask)==2)/20)}, \n",
    "        #                         stroma: {round(np.sum(np.array(Mask)==3)/20)}, type4: {round(np.sum(np.array(Mask)==4)/20)}\"\"\")\n",
    "\n",
    "        # viable = round(np.sum(np.array(Mask) == 1) / 20)\n",
    "        # necrosis = round(np.sum(np.array(Mask) == 2) / 20)\n",
    "        # stroma = round(np.sum(np.array(Mask) == 3) / 20)\n",
    "        # type4 = round(np.sum(np.array(Mask) == 4)/8 ) \n",
    "        viable = 500\n",
    "        necrosis = 500\n",
    "        stroma = 500\n",
    "        type4 = 500\n",
    "        dic[(data[i])] ={\n",
    "            'stroma': stroma,\n",
    "            'viable': viable,\n",
    "            'necrosis': necrosis,\n",
    "            'type4': type4,\n",
    "        }\n",
    "    return dic\n",
    "\n",
    "\n",
    "#Get the bag length\n",
    "Settings_val = slide_setting(val_data,val_label)\n",
    "\n",
    "#Insert the OTSU\n",
    "def insert_otsu(settingslides,adjust_otsu_type):\n",
    "    for key, adjust_otsu in zip(settingslides.keys(), adjust_otsu_type):\n",
    "        settingslides[key]['adjust_otsu'] = adjust_otsu\n",
    "    return settingslides\n",
    "\n",
    "\n",
    "adjust_otsu_val= split_df[split_df[\"dataset\"] ==\"validation\"][\"OSTU\"].to_list()\n",
    "Settings_val =insert_otsu(Settings_val,adjust_otsu_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load validation WSI\n",
    "if len(val_data)>0:\n",
    "    slides_val = {}\n",
    "    num_bags_val = {}\n",
    "    annotations_val= {}\n",
    "    tissue_masks_val = {}\n",
    "    label_masks_val = {}\n",
    "    for i, slide_ID in enumerate(val_data):\n",
    "        slides_val[slide_ID] = openslide.OpenSlide(slide_ID)\n",
    "        annotations_val[slide_ID] = read_Aaron_annotations(val_label[i])\n",
    "        num_bags_val[slide_ID] = [Settings_val[slide_ID]['stroma'],Settings_val[slide_ID]['viable'],Settings_val[slide_ID]['necrosis'],Settings_val[slide_ID]['type4']]    \n",
    "        tissue_masks_val[slide_ID] = generate_tissue_mask(slides_val[slide_ID],unit=unit,adjust_otsu=Settings_val[slide_ID]['adjust_otsu'])\n",
    "        label_masks_val[slide_ID] = generate_label_mask(slides_val[slide_ID], annotations_val[slide_ID], annotation_label_mapping, unit)\n",
    "\n",
    "#Find the train bag total length\n",
    "val_bag_len =[0,0,0,0]\n",
    "for idx,key in num_bags_val.items():\n",
    "    val_bag_len[0] += key[0] \n",
    "    val_bag_len[1] += key[1] \n",
    "    val_bag_len[2] += key[2] \n",
    "    val_bag_len[3] += key[3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Test Slide Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find settings for test slides\n",
    "def slide_setting(data,label):\n",
    "    dic = {}\n",
    "    for i in range(len(data)):\n",
    "        Annotations=read_Aaron_annotations(label[i])\n",
    "        slide = openslide.OpenSlide(data[i])\n",
    "        Mask = generate_label_mask(slide,Annotations,annotation_label_mapping,256)\n",
    "        # print(f\"\"\"{i+1}st slide: viable: {round(np.sum(np.array(Mask)==1)/20)},\n",
    "        #                         necrosis: {round(np.sum(np.array(Mask)==2)/20)}, \n",
    "        #                         stroma: {round(np.sum(np.array(Mask)==3)/20)}, type4: {round(np.sum(np.array(Mask)==4)/20)}\"\"\")\n",
    "\n",
    "        # viable = round(np.sum(np.array(Mask) == 1) / 20)\n",
    "        # necrosis = round(np.sum(np.array(Mask) == 2) / 20)\n",
    "        # stroma = round(np.sum(np.array(Mask) == 3) / 20)\n",
    "        # type4 = round(np.sum(np.array(Mask) == 4)/8 ) \n",
    "        viable = 500\n",
    "        necrosis = 500\n",
    "        stroma = 500\n",
    "        type4 = 500\n",
    "        dic[(data[i])] ={\n",
    "            'stroma': stroma,\n",
    "            'viable': viable,\n",
    "            'necrosis': necrosis,\n",
    "            'type4': type4,\n",
    "        }\n",
    "    return dic\n",
    "\n",
    "\n",
    "#Get the bag length\n",
    "Settings_test = slide_setting(test_data,test_label)\n",
    "\n",
    "#Insert the OTSU\n",
    "def insert_otsu(settingslides,adjust_otsu_type):\n",
    "    for key, adjust_otsu in zip(settingslides.keys(), adjust_otsu_type):\n",
    "        settingslides[key]['adjust_otsu'] = adjust_otsu\n",
    "    return settingslides\n",
    "\n",
    "\n",
    "adjust_otsu_test= split_df[split_df[\"dataset\"] ==\"test\"][\"OSTU\"].to_list()\n",
    "Settings_test =insert_otsu(Settings_test,adjust_otsu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test WSI\n",
    "if len(test_data)>0:\n",
    "    slides_test= {}\n",
    "    num_bags_test = {}\n",
    "    annotations_test= {}\n",
    "    tissue_masks_test = {}\n",
    "    label_masks_test = {}\n",
    "    for i, slide_ID in enumerate(test_data):\n",
    "        slides_test[slide_ID] = openslide.OpenSlide(slide_ID)\n",
    "        annotations_test[slide_ID] = read_Aaron_annotations(test_label[i])\n",
    "        num_bags_test[slide_ID] = [Settings_test[slide_ID]['stroma'],Settings_test[slide_ID]['viable'],Settings_test[slide_ID]['necrosis'],Settings_test[slide_ID]['type4']]    \n",
    "        tissue_masks_test[slide_ID] = generate_tissue_mask(slides_test[slide_ID],unit=unit,adjust_otsu=Settings_test[slide_ID]['adjust_otsu'])\n",
    "        label_masks_test[slide_ID] = generate_label_mask(slides_test[slide_ID], annotations_test[slide_ID], annotation_label_mapping, unit)\n",
    "\n",
    "#Find the train bag total length\n",
    "test_bag_len =[0,0,0,0]\n",
    "for idx,key in num_bags_test.items():\n",
    "    test_bag_len[0] += key[0] \n",
    "    test_bag_len[1] += key[1] \n",
    "    test_bag_len[2] += key[2] \n",
    "    test_bag_len[3] += key[3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     project= \"osteosarcoma- ModelTrain\",\n",
    "#     name = \"Generalization\",\n",
    "#     config={\n",
    "#         \"epochs\":6,\n",
    "#         \"batch_size\": 1,\n",
    "#         \"lr\": 0.000001,\n",
    "#     }\n",
    "# )\n",
    "# config = wandb.config\n",
    "# device = torch.device(\"cuda:6\")\n",
    "# torch.cuda.set_device(device)\n",
    "# model = Attention_modern_multi(load_vgg16(),True)\n",
    "# model = model.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(),lr=0.00005, betas=(0.9, 0.999), weight_decay =10e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.2)\n",
    "\n",
    "# # Dataset_train = create_dataset_mixpatch(slides_train,\n",
    "# #                                   tissue_masks_train, label_masks_train, \n",
    "# #                                   train_bag_len, level, patch_shape,length_bag_mean = 10)\n",
    "# if len(slides_val)>0:\n",
    "#     # Dataset_val = create_dataset_mixpatch(slides_val,\n",
    "#     #                               tissue_masks_val, label_masks_val, \n",
    "#     #                               val_bag_len, level, patch_shape,length_bag_mean = 10)\n",
    "#     model, Train_loss, Train_accuracy, Val_loss, Val_accuracy = Train(model, Dataset_train, optimizer, scheduler, validation=True, Dataset_val = Dataset_val)\n",
    "# else:\n",
    "#     model, Train_loss, Train_accuracy, Val_loss, Val_accuracy = Train(model, Dataset_train, optimizer, scheduler, validation=False, Dataset_val = None)\n",
    "\n",
    "# # save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5B Validation and Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B.1 Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def val(model, Dataloader_val):\n",
    "#     val_error = 0. \n",
    "#     pred_labels = []    \n",
    "#     for batch_idx, (data, label) in enumerate(Dataloader_val):\n",
    "#         bag_label = label\n",
    "#         data, bag_label = data.cuda(), bag_label.cuda()\n",
    "#         data, bag_label = Variable(data,requires_grad=False), Variable(bag_label,requires_grad=False)\n",
    "#         error, pred, _ = model.calculate_classification_error(data, bag_label)\n",
    "#         pred_labels.append(pred.data.cpu().item())\n",
    "#         val_error += error\n",
    "#         if batch_idx%50 ==0:\n",
    "#             print(f\"{batch_idx}th Validation accuracy:{1-(val_error/(batch_idx+1)):.3f}\")\n",
    "#         del data\n",
    "#         del bag_label\n",
    "#     val_error /= len(Dataloader_val)\n",
    "#     return pred_labels, 1-val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load model\n",
    "# path = \"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/mixpatch_final.pth\"\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = Attention_modern_multi(load_vgg16())\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Import test data\n",
    "# # Dataset_val = create_dataset_mixpatch(slides_val,\n",
    "# #                                   tissue_masks_val, label_masks_val, \n",
    "# #                                   val_bag_len, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Test accuracy\n",
    "# val_accuracy_list= []\n",
    "# Dataloader_val = data_utils.DataLoader(Dataset_val, batch_size = 1, shuffle = False)\n",
    "# pred_labels, val_accuracy = val(model, Dataloader_val)\n",
    "# val_accuracy_list.append(val_accuracy)\n",
    "# print(\"val_accuracy = {:.3f}\".format(val_accuracy))\n",
    "\n",
    "\n",
    "# #write into json\n",
    "# # with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/validation.json\",\"w\") as f:\n",
    "# #     json.dump(pred_labels,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B.1 Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, Dataloader_test):\n",
    "    test_error = 0. \n",
    "    pred_labels = []   \n",
    "    true_labels = [] \n",
    "    for batch_idx, (data, label) in enumerate(Dataloader_test):\n",
    "        bag_label = label\n",
    "        data, bag_label = data.cuda(), bag_label.cuda()\n",
    "        data, bag_label = Variable(data,requires_grad=False), Variable(bag_label,requires_grad=False)\n",
    "        error, pred, prob = model.calculate_classification_error(data, bag_label)\n",
    "        print(prob.cpu().data.numpy()[0])\n",
    "        pred_labels.append(pred.data.cpu().item())\n",
    "        true_labels.append(bag_label.data.cpu().item())\n",
    "        test_error += error\n",
    "        if batch_idx%50 ==0:\n",
    "            print(f\"{batch_idx}th test accuracy:{1-(test_error/(batch_idx+1)):.3f}\")\n",
    "        del data\n",
    "        del bag_label\n",
    "    test_error /= len(Dataloader_test)\n",
    "    return pred_labels, true_labels,1-test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# path = \"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/mixpatch_final.pth\"\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = Attention_modern_multi(load_vgg16())\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # #Import test data\n",
    "# # Dataset_test = create_dataset_mixpatch(slides_test,\n",
    "# #                                   tissue_masks_test, label_masks_test, \n",
    "# #                                   test_bag_len, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Test accuracy\n",
    "# test_accuracy_list= []\n",
    "# Dataloader_test = data_utils.DataLoader(Dataset_test, batch_size = 1, shuffle = False)\n",
    "# pred_labels_test, test_accuracy = test(model, Dataloader_test)\n",
    "# test_accuracy_list.append(test_accuracy)\n",
    "# print(\"epoch={}, test_accuracy = {:.3f}\".format(i, test_accuracy))\n",
    "\n",
    "# #write into json\n",
    "# with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test.json\",\"w\") as f:\n",
    "#     json.dump(pred_labels_test,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5c. Validation and Test Classification Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5c.1 Validation classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import predicted labels\n",
    "# f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/validation.json\")\n",
    "# val = json.load(f)\n",
    "\n",
    "# listname = ['stroma', 'viable', 'necrosis', 'type4']\n",
    "# #Get classification result\n",
    "# for i in range(len(listname)):\n",
    "#     for j in range(len(listname)):\n",
    "#         class_len = int(len(val)/4)\n",
    "#         result = np.sum(np.array(val[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "#         print(f\"{listname[i]}: classification result for {listname[j]}: {result*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5c.1 Test classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import predicted labels\n",
    "# f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test.json\")\n",
    "# test = json.load(f)\n",
    "\n",
    "# listname = ['stroma', 'viable', 'necrosis', 'type4']\n",
    "# #Get classification result\n",
    "# for i in range(len(listname)):\n",
    "#     for j in range(len(listname)):\n",
    "#         class_len = int(len(test)/4)\n",
    "#         result = np.sum(np.array(test[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "#         print(f\"{listname[i]}: classification result for {listname[j]}: {result*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test data slide level accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Construct bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSbags_random_oneslide(data_utils.Dataset):\n",
    "    def __init__(self, slide_ob, mask_tissue, mask_label, level, patch_shape, length_bag_mean, num_bags, transform):\n",
    "        self.slide_ob = slide_ob\n",
    "        self.mask_tissue = mask_tissue\n",
    "        self.mask_label = mask_label\n",
    "        self.level = level\n",
    "        self.patch_shape =patch_shape\n",
    "        self.length_bag_mean = length_bag_mean\n",
    "        self.num_bags = num_bags\n",
    "        self.transform = transform\n",
    "        self.unit = int(self.slide_ob.dimensions[0]/mask_tissue.shape[1])\n",
    "        self.bags_list, self.labels_list = self._create_bags()  \n",
    "    def _create_bags(self):            \n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "        for label in range(len(self.num_bags)):         \n",
    "            ROW, COL = np.where((self.mask_tissue==1)&(self.mask_label==label+1))\n",
    "            for bag_idx in range(self.num_bags[label]):\n",
    "                if len(ROW) <=self.length_bag_mean:\n",
    "                    pass\n",
    "                else: \n",
    "                    length_bag = binom.rvs (n=int(self.length_bag_mean*2), p=0.5)\n",
    "                    indices = np.random.randint(0,len(ROW),length_bag)\n",
    "                    bags_list.append((ROW[indices], COL[indices]))\n",
    "                    labels_list.append(label)\n",
    "        return bags_list, labels_list\n",
    "    def _pack_one_bag(self,row_list, col_list):\n",
    "        Bag = []\n",
    "        for i in range(len(row_list)):\n",
    "            row_unit, col_unit = row_list[i], col_list[i]\n",
    "            factor = self.slide_ob.level_downsamples[self.level]\n",
    "            upperLeft_x = int(col_unit * self.unit + self.unit/2 - self.patch_shape/2*factor)\n",
    "            upperLeft_y = int(row_unit * self.unit + self.unit/2 - self.patch_shape/2*factor)\n",
    "            patch = self.slide_ob.read_region((upperLeft_x, upperLeft_y),self.level,(self.patch_shape,self.patch_shape))\n",
    "            patch = Image.fromarray(np.array(patch)[:,:,:3])\n",
    "            if self.transform is not None:\n",
    "                patch = self.transform(patch)\n",
    "            Bag.append(patch)\n",
    "        Bag = np.stack(Bag,axis=0)\n",
    "        return Bag  \n",
    "    def __len__(self):\n",
    "        return len(self.bags_list)  \n",
    "    def __getitem__(self, index):\n",
    "        row_list, col_list = self.bags_list[index]\n",
    "        bag = self._pack_one_bag(row_list, col_list)\n",
    "        label = self.labels_list[index]\n",
    "        return bag, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_mixbag(slides, tissue_masks, label_masks, num_bags, level, patch_shape,length_bag_mean = 10):\n",
    "    \"\"\"\n",
    "    Generate data loaders\n",
    "    - Input\n",
    "        slides: dictionary {'slide_ID':slide_ob}\n",
    "        tissue_masks: dictionary {'slide_ID':array}\n",
    "        label_masks: dictionary {'slide_ID':array}\n",
    "        num_bags:dict{'slide_ID':list}\n",
    "        level:int\n",
    "        patch:int\n",
    "    - Return\n",
    "        Dataset\n",
    "    \"\"\"\n",
    "    # Training loaders\n",
    "    dataset = TSbags_random_oneslide(slide_ob = slides,\n",
    "                                        mask_tissue = tissue_masks, \n",
    "                                        mask_label = label_masks, \n",
    "                                        level = level, \n",
    "                                        patch_shape = patch_shape, \n",
    "                                        length_bag_mean = length_bag_mean, \n",
    "                                        num_bags = num_bags, \n",
    "                                        transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))      \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet():\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "\n",
    "    indices = [-3, -1]\n",
    "    for i in indices:  \n",
    "        for param in model.layer3[i].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # for layer_num,child in enumerate(model.children()):\n",
    "    #     for param in child.parameters():\n",
    "    #         print(f'Layer {layer_num}, requires_grad: {param.requires_grad}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Patient ID:\n",
    "test_data_dic = {\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 11.44.02.ndpi\":28,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 11.53.52.ndpi\":28,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.05.18.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.15.35.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.22.28.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.33.26.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.44.58.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 12.58.15.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.11.39.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.26.15.ndpi\":32,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.34.06.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.44.45.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.53.57.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.02.46.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.11.24.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.21.42.ndpi\":33,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.33.13.ndpi\":34,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.43.06.ndpi\":34,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 14.54.44.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.04.39.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.16.39.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.24.44.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.35.24.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.43.44.ndpi\":35,\n",
    "\"/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 15.53.59.ndpi\":35\n",
    "}\n",
    "# with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\",\"w\") as f:\n",
    "#     json.dump(test_data_dic,f)\n",
    "f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\")\n",
    "test_data_dic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #step0\n",
    "# # load model\n",
    "# f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\")\n",
    "# test_data_dic = json.load(f)\n",
    "# path = \"/cis/home/jhu104/osteosarcoma/model_vgg16tune/ml_300_epoch.pth\"\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = Attention_modern_multi(load_vgg16_tune())\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model = model.to(device)\n",
    "# set_bag_length =800 \n",
    "# test_bag_len_slide = [set_bag_length,set_bag_length,set_bag_length,set_bag_length]\n",
    "\n",
    "\n",
    "#     # 'stroma':1,\n",
    "#     # 'viable':2,\n",
    "#     # 'necrosis':3,\n",
    "#     # 'type4':4\n",
    "\n",
    "\n",
    "# #step1\n",
    "# #Prediction accuracy    \n",
    "# def prediction_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     #Get classification result\n",
    "#     for i in range(label_type):\n",
    "#         for j in range(len(listname)):\n",
    "#             class_len = int(len(pred)/label_type)\n",
    "#             result = np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "#             print(f\"{listname[label_name[i]]}: classification result for {listname[j]}: {result*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# #step2\n",
    "# #Prediction patient accuracy\n",
    "# def prediction_patient_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     stroma_acc = []\n",
    "#     viable_acc= []\n",
    "#     necrosis_acc = []\n",
    "#     cartilage_acc =[]\n",
    "#     #Get classification result\n",
    "#     for i,type in enumerate(label_name):\n",
    "#         # print(f\"prediction type:{pred}\")\n",
    "#         class_len = int(len(pred)/label_type)\n",
    "#         result = (np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==type)/class_len)\n",
    "#         if type == 0:\n",
    "#             stroma_acc.append(result)\n",
    "#         elif type ==1:\n",
    "#             viable_acc.append(result)\n",
    "#         elif type ==2:\n",
    "#             necrosis_acc.append(result)\n",
    "#         elif type ==3:\n",
    "#             cartilage_acc.append(result)\n",
    "#     return   stroma_acc,viable_acc,necrosis_acc,cartilage_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #step3\n",
    "# #Compute test accuracy\n",
    "# # dict(itertools.islice(test_data_dic.items(), 2,16))\n",
    "# # filtered_dict = {key: value for key, value in test_data_dic.items() if value == 33}\n",
    "# patient_list = [28,32,33,34,35]\n",
    "# patient_metrics = {patient_id: {'stroma': [], 'viable': [], 'necrosis': [], 'cartilage': []} for patient_id in patient_list}\n",
    "# test_accuracy_list = {} #####Slide level accuracy\n",
    "\n",
    "# for keys,patient_id in test_data_dic.items():\n",
    "#     Dataset_test = create_dataset_mixbag(slides_test[keys],\n",
    "#                                     tissue_masks_test[keys], label_masks_test[keys], \n",
    "#                                     test_bag_len_slide, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "#     print(f\"{patient_id}th patient: {keys}\")\n",
    "#     #Test accuracy\n",
    "#     Dataloader_test = data_utils.DataLoader(Dataset_test, batch_size = 1, shuffle = False)\n",
    "#     pred_labels_test, true_labels,test_accuracy = test(model, Dataloader_test)\n",
    "#     basename = os.path.basename(keys)\n",
    "#     test_accuracy_list[basename]=round(test_accuracy,3)\n",
    "    \n",
    "#     #Print slide accuracy\n",
    "#     print(\"test_accuracy = {:.3f}\".format(test_accuracy))\n",
    "#     print(\"Classification Results\")\n",
    "#     prediction_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "#     stroma_acc,viable_acc,necrosis_acc,cartilage_acc=prediction_patient_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "    \n",
    "#    # Append the results for this key to the patient's metrics\n",
    "#     if stroma_acc:  \n",
    "#         patient_metrics[patient_id]['stroma'].append(stroma_acc[0])\n",
    "#     if viable_acc:  # \n",
    "#         patient_metrics[patient_id]['viable'].append(viable_acc[0])\n",
    "#     if necrosis_acc: \n",
    "#         patient_metrics[patient_id]['necrosis'].append(necrosis_acc[0])\n",
    "#     if cartilage_acc:  #\n",
    "#         patient_metrics[patient_id]['cartilage'].append(cartilage_acc[0])\n",
    "#     print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# #Step4\n",
    "# #Compute patient level accuracy\n",
    "# print(\"Patient Level Accuracy\")\n",
    "# for patient_id, metrics in patient_metrics.items():\n",
    "#     print(\"\")\n",
    "#     for metric ,values in metrics.items():\n",
    "#         print(f\"{patient_id}th: {metric}%: {np.mean(np.array(values))*100:.2f}(std:{np.std(np.array(values))*100:.2f})\")\n",
    "\n",
    "# #step5\n",
    "# #Mean Acc and Std\n",
    "# print(\"\")\n",
    "# print(f\"Mean Accuracy:{np.mean(np.array(list(test_accuracy_list.values())))*100:.2f}(std:{np.std(np.array(list(test_accuracy_list.values())))*100:.2f})\")\n",
    "# with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/slide_accuracy\", \"w\") as f:\n",
    "#     # Use json.dump to write the dictionary to the file with indentation\n",
    "#     json.dump(test_accuracy_list, f, indent=4)  \n",
    "\n",
    "# test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #step0\n",
    "# # load model\n",
    "# f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\")\n",
    "# test_data_dic = json.load(f)\n",
    "# path = \"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/ml_final.pth\"\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = Attention_modern_multi(load_resnet())\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model = model.to(device)\n",
    "# set_bag_length =800\n",
    "# test_bag_len_slide = [set_bag_length,set_bag_length,set_bag_length,set_bag_length]\n",
    "\n",
    "\n",
    "#     # 'stroma':1,\n",
    "#     # 'viable':2,\n",
    "#     # 'necrosis':3,\n",
    "#     # 'type4':4\n",
    "\n",
    "\n",
    "# #step1\n",
    "# #Prediction accuracy    \n",
    "# def prediction_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     #Get classification result\n",
    "#     for i in range(label_type):\n",
    "#         for j in range(len(listname)):\n",
    "#             class_len = int(len(pred)/label_type)\n",
    "#             result = np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "#             print(f\"{listname[label_name[i]]}: classification result for {listname[j]}: {result*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# #step2\n",
    "# #Prediction patient accuracy\n",
    "# def prediction_patient_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     stroma_acc = []\n",
    "#     viable_acc= []\n",
    "#     necrosis_acc = []\n",
    "#     cartilage_acc =[]\n",
    "#     #Get classification result\n",
    "#     for i,type in enumerate(label_name):\n",
    "#         # print(f\"prediction type:{pred}\")\n",
    "#         class_len = int(len(pred)/label_type)\n",
    "#         result = (np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==type)/class_len)\n",
    "#         if type == 0:\n",
    "#             stroma_acc.append(result)\n",
    "#         elif type ==1:\n",
    "#             viable_acc.append(result)\n",
    "#         elif type ==2:\n",
    "#             necrosis_acc.append(result)\n",
    "#         elif type ==3:\n",
    "#             cartilage_acc.append(result)\n",
    "#     return   stroma_acc,viable_acc,necrosis_acc,cartilage_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #step3\n",
    "# #Compute test accuracy\n",
    "# # dict(itertools.islice(test_data_dic.items(), 2,16))\n",
    "# # filtered_dict = {key: value for key, value in test_data_dic.items() if value == 33}\n",
    "# patient_list = [28,32,33,34,35]\n",
    "# patient_metrics = {patient_id: {'stroma': [], 'viable': [], 'necrosis': [], 'cartilage': []} for patient_id in patient_list}\n",
    "# test_accuracy_list = {} #####Slide level accuracy\n",
    "\n",
    "# for keys,patient_id in test_data_dic.items():\n",
    "#     Dataset_test = create_dataset_mixbag(slides_test[keys],\n",
    "#                                     tissue_masks_test[keys], label_masks_test[keys], \n",
    "#                                     test_bag_len_slide, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "#     print(f\"{patient_id}th patient: {keys}\")\n",
    "#     #Test accuracy\n",
    "#     Dataloader_test = data_utils.DataLoader(Dataset_test, batch_size = 1, shuffle = False)\n",
    "#     pred_labels_test, true_labels,test_accuracy = test(model, Dataloader_test)\n",
    "#     basename = os.path.basename(keys)\n",
    "#     test_accuracy_list[basename]=round(test_accuracy,3)\n",
    "    \n",
    "#     #Print slide accuracy\n",
    "#     print(\"test_accuracy = {:.3f}\".format(test_accuracy))\n",
    "#     print(\"Classification Results\")\n",
    "#     prediction_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "#     stroma_acc,viable_acc,necrosis_acc,cartilage_acc=prediction_patient_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "    \n",
    "#    # Append the results for this key to the patient's metrics\n",
    "#     if stroma_acc:  \n",
    "#         patient_metrics[patient_id]['stroma'].append(stroma_acc[0])\n",
    "#     if viable_acc:  # \n",
    "#         patient_metrics[patient_id]['viable'].append(viable_acc[0])\n",
    "#     if necrosis_acc: \n",
    "#         patient_metrics[patient_id]['necrosis'].append(necrosis_acc[0])\n",
    "#     if cartilage_acc:  #\n",
    "#         patient_metrics[patient_id]['cartilage'].append(cartilage_acc[0])\n",
    "#     print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# #Step4\n",
    "# #Compute patient level accuracy\n",
    "# print(\"Patient Level Accuracy\")\n",
    "# for patient_id, metrics in patient_metrics.items():\n",
    "#     print(\"\")\n",
    "#     for metric ,values in metrics.items():\n",
    "#         print(f\"{patient_id}th: {metric}%: {np.mean(np.array(values))*100:.2f}(std:{np.std(np.array(values))*100:.2f})\")\n",
    "\n",
    "# #step5\n",
    "# #Mean Acc and Std\n",
    "# print(\"\")\n",
    "# print(f\"Mean Accuracy:{np.mean(np.array(list(test_accuracy_list.values())))*100:.2f}(std:{np.std(np.array(list(test_accuracy_list.values())))*100:.2f})\")\n",
    "# with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/slide_accuracy\", \"w\") as f:\n",
    "#     # Use json.dump to write the dictionary to the file with indentation\n",
    "#     json.dump(test_accuracy_list, f, indent=4)  \n",
    "\n",
    "# test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #step0\n",
    "# # load model\n",
    "# f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\")\n",
    "# test_data_dic = json.load(f)\n",
    "# path = \"/cis/home/jhu104/osteosarcoma/model_experiment_setting_tuning/ml_final.pth\"\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = Attention_modern_multi(load_resnet())\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model = model.to(device)\n",
    "# set_bag_length =800\n",
    "# test_bag_len_slide = [set_bag_length,set_bag_length,set_bag_length,set_bag_length]\n",
    "\n",
    "\n",
    "#     # 'stroma':1,\n",
    "#     # 'viable':2,\n",
    "#     # 'necrosis':3,\n",
    "#     # 'type4':4\n",
    "\n",
    "\n",
    "# #step1\n",
    "# #Prediction accuracy    \n",
    "# def prediction_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     #Get classification result\n",
    "#     for i in range(label_type):\n",
    "#         for j in range(len(listname)):\n",
    "#             class_len = int(len(pred)/label_type)\n",
    "#             result = np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "#             print(f\"{listname[label_name[i]]}: classification result for {listname[j]}: {result*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# #step2\n",
    "# #Prediction patient accuracy\n",
    "# def prediction_patient_accuracy(pred,true,test_bag_len_slide):\n",
    "#     listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "#     label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "#     label_name = np.unique(true)\n",
    "#     stroma_acc = []\n",
    "#     viable_acc= []\n",
    "#     necrosis_acc = []\n",
    "#     cartilage_acc =[]\n",
    "#     #Get classification result\n",
    "#     for i,type in enumerate(label_name):\n",
    "#         # print(f\"prediction type:{pred}\")\n",
    "#         class_len = int(len(pred)/label_type)\n",
    "#         result = (np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==type)/class_len)\n",
    "#         if type == 0:\n",
    "#             stroma_acc.append(result)\n",
    "#         elif type ==1:\n",
    "#             viable_acc.append(result)\n",
    "#         elif type ==2:\n",
    "#             necrosis_acc.append(result)\n",
    "#         elif type ==3:\n",
    "#             cartilage_acc.append(result)\n",
    "#     return   stroma_acc,viable_acc,necrosis_acc,cartilage_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #step3\n",
    "# #Compute test accuracy\n",
    "# # dict(itertools.islice(test_data_dic.items(), 2,16))\n",
    "# # filtered_dict = {key: value for key, value in test_data_dic.items() if value == 33}\n",
    "# patient_list = [28,32,33,34,35]\n",
    "# patient_metrics = {patient_id: {'stroma': [], 'viable': [], 'necrosis': [], 'cartilage': []} for patient_id in patient_list}\n",
    "# test_accuracy_list = {} #####Slide level accuracy\n",
    "\n",
    "# for keys,patient_id in test_data_dic.items():\n",
    "#     Dataset_test = create_dataset_mixbag(slides_test[keys],\n",
    "#                                     tissue_masks_test[keys], label_masks_test[keys], \n",
    "#                                     test_bag_len_slide, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "#     print(f\"{patient_id}th patient: {keys}\")\n",
    "#     #Test accuracy\n",
    "#     Dataloader_test = data_utils.DataLoader(Dataset_test, batch_size = 1, shuffle = False)\n",
    "#     pred_labels_test, true_labels,test_accuracy = test(model, Dataloader_test)\n",
    "#     basename = os.path.basename(keys)\n",
    "#     test_accuracy_list[basename]=round(test_accuracy,3)\n",
    "    \n",
    "#     #Print slide accuracy\n",
    "#     print(\"test_accuracy = {:.3f}\".format(test_accuracy))\n",
    "#     print(\"Classification Results\")\n",
    "#     prediction_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "#     stroma_acc,viable_acc,necrosis_acc,cartilage_acc=prediction_patient_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "    \n",
    "#    # Append the results for this key to the patient's metrics\n",
    "#     if stroma_acc:  \n",
    "#         patient_metrics[patient_id]['stroma'].append(stroma_acc[0])\n",
    "#     if viable_acc:  # \n",
    "#         patient_metrics[patient_id]['viable'].append(viable_acc[0])\n",
    "#     if necrosis_acc: \n",
    "#         patient_metrics[patient_id]['necrosis'].append(necrosis_acc[0])\n",
    "#     if cartilage_acc:  #\n",
    "#         patient_metrics[patient_id]['cartilage'].append(cartilage_acc[0])\n",
    "#     print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# #Step4\n",
    "# #Compute patient level accuracy\n",
    "# print(\"Patient Level Accuracy\")\n",
    "# for patient_id, metrics in patient_metrics.items():\n",
    "#     print(\"\")\n",
    "#     for metric ,values in metrics.items():\n",
    "#         print(f\"{patient_id}th: {metric}%: {np.mean(np.array(values))*100:.2f}(std:{np.std(np.array(values))*100:.2f})\")\n",
    "\n",
    "# #step5\n",
    "# #Mean Acc and Std\n",
    "# print(\"\")\n",
    "# print(f\"Mean Accuracy:{np.mean(np.array(list(test_accuracy_list.values())))*100:.2f}(std:{np.std(np.array(list(test_accuracy_list.values())))*100:.2f})\")\n",
    "# with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/slide_accuracy\", \"w\") as f:\n",
    "#     # Use json.dump to write the dictionary to the file with indentation\n",
    "#     json.dump(test_accuracy_list, f, indent=4)  \n",
    "\n",
    "# test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the data\n",
    "# data = {\n",
    "#     'Patient': ['28th', '32th', '33th', '34th', '35th'],\n",
    "#     'Stroma%': ['100.00 (0.00)', '47.44 (35.31)', '2.00 (0.00)', '100.00 (0.00)', '99.88 (0.19)'],\n",
    "#     'Viable%': ['100.00 (0.00)', '93.55 (13.50)', '98.59 (1.66)', '88.88 (10.25)', '99.75 (0.36)'],\n",
    "#     'Necrosis%': ['100.00 (0.00)', '100.00 (0.00)', '99.94 (0.10)', 'nan (nan)', '63.43 (27.77)'],\n",
    "#     'Cartilage%': ['nan (nan)', 'nan (nan)', 'nan (nan)', 'nan (nan)', '93.50 (0.00)'],\n",
    "# }\n",
    "\n",
    "# # Create DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}\n",
    "# test_accuracy_pd = pd.DataFrame(test_accuracy_list_updated.items())\n",
    "# test_accuracy_pd =test_accuracy_pd.rename(columns={0:\"Patient_ID\",1:\"Test Accuracy\"})\n",
    "# test_accuracy_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /cis/home/jhu104/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33th patient: /cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.44.45.ndpi\n",
      "[0.10259888 0.04425316 0.8398019  0.01334603]\n",
      "0th test accuracy:1.000\n",
      "[0.06118904 0.13062435 0.7958081  0.01237856]\n",
      "[0.20888805 0.06023009 0.71654296 0.01433888]\n",
      "[0.36280367 0.13766854 0.4742499  0.02527785]\n",
      "[0.23893695 0.04342498 0.70030206 0.01733601]\n",
      "[0.03622619 0.05563888 0.8960124  0.01212254]\n",
      "[0.04442684 0.02691351 0.9196917  0.00896799]\n",
      "[0.09479189 0.1640812  0.72520256 0.01592427]\n",
      "[0.30808234 0.11049522 0.562839   0.01858352]\n",
      "[0.0371086  0.02340599 0.9297299  0.00975547]\n",
      "[0.06684529 0.0461923  0.87725693 0.00970541]\n",
      "[0.37098396 0.07024921 0.5310751  0.02769169]\n",
      "[0.07804036 0.04398789 0.86840796 0.00956383]\n",
      "[0.1401288  0.04788728 0.80235994 0.00962399]\n",
      "[0.09549081 0.05659099 0.8405746  0.00734355]\n",
      "[0.06281949 0.04369885 0.8822428  0.01123885]\n",
      "[0.06481127 0.0436315  0.8783046  0.01325257]\n",
      "[0.18536572 0.15826204 0.64361143 0.01276085]\n",
      "[0.66074467 0.12548988 0.14462602 0.06913945]\n",
      "[0.05406052 0.02814047 0.9079451  0.00985401]\n",
      "[0.0324049  0.02356849 0.93400323 0.01002336]\n",
      "[0.03641922 0.02170126 0.9311553  0.01072424]\n",
      "[0.10666218 0.05173479 0.8275514  0.01405165]\n",
      "[0.03636739 0.04131124 0.9123747  0.00994674]\n",
      "[0.11027491 0.11215313 0.7515525  0.02601947]\n",
      "[0.07405482 0.13663985 0.7698545  0.0194508 ]\n",
      "[0.04942261 0.25260794 0.6734574  0.02451209]\n",
      "[0.08867367 0.27374834 0.6139373  0.02364066]\n",
      "[0.19864793 0.2253929  0.5589127  0.01704647]\n",
      "[0.46897247 0.01918905 0.4624748  0.04936363]\n",
      "[0.11892251 0.43192005 0.40134713 0.04781025]\n",
      "[0.28010923 0.09268972 0.61011255 0.0170885 ]\n",
      "[0.05008621 0.07909327 0.85963446 0.01118614]\n",
      "[0.2433411  0.07000831 0.6769869  0.00966379]\n",
      "[0.08974433 0.03101176 0.86229587 0.0169481 ]\n",
      "[0.04966957 0.03845701 0.9042525  0.00762083]\n",
      "[0.04186204 0.14360374 0.8042064  0.01032792]\n",
      "[0.1185201  0.260867   0.6009106  0.01970233]\n",
      "[0.04589723 0.40286684 0.5323618  0.01887413]\n",
      "[0.08534381 0.0862129  0.8148337  0.01360954]\n",
      "[0.32848248 0.04197919 0.60599124 0.02354709]\n",
      "[0.05793337 0.09862334 0.82106906 0.02237429]\n",
      "[0.16733404 0.05292401 0.7625621  0.01717981]\n",
      "[0.06250864 0.05932616 0.86575145 0.01241368]\n",
      "[0.06307846 0.09578248 0.83405346 0.00708563]\n",
      "[0.03373019 0.04835415 0.90759563 0.01031999]\n",
      "[0.08922663 0.02649032 0.8738788  0.0104042 ]\n",
      "[0.09402917 0.03615335 0.85462016 0.01519722]\n",
      "[0.6431646  0.08056778 0.25167644 0.02459117]\n",
      "[0.03400456 0.20262466 0.7448721  0.0184987 ]\n",
      "[0.0613696  0.0655153  0.86454684 0.00856828]\n",
      "50th test accuracy:0.922\n",
      "[0.27322522 0.06064112 0.64901274 0.0171209 ]\n",
      "[0.09222986 0.1102895  0.7849003  0.01258036]\n",
      "[0.03544157 0.02883165 0.92656887 0.00915788]\n",
      "[0.0374302  0.02087188 0.9321878  0.00951017]\n",
      "[0.07881657 0.05594929 0.8567153  0.00851877]\n",
      "[0.24324656 0.03907335 0.69982445 0.01785572]\n",
      "[0.34098044 0.03625065 0.60704994 0.01571889]\n",
      "[0.56984055 0.14360587 0.26634172 0.02021181]\n",
      "[0.08297203 0.0188075  0.884841   0.01337951]\n",
      "[0.0534579  0.0311431  0.9065925  0.00880648]\n",
      "[0.19882786 0.1148672  0.67381597 0.01248902]\n",
      "[0.09833633 0.2743633  0.6017745  0.02552588]\n",
      "[0.06116013 0.315201   0.59463394 0.02900489]\n",
      "[0.10084432 0.0600118  0.8265676  0.01257627]\n",
      "[0.12442684 0.0357528  0.82816726 0.01165305]\n",
      "[0.36298606 0.08812545 0.5188026  0.03008586]\n",
      "[0.04189764 0.04244493 0.90446645 0.01119094]\n",
      "[0.07113524 0.02775164 0.89006054 0.01105255]\n",
      "[0.08206018 0.05554907 0.8543798  0.00801108]\n",
      "[0.03733448 0.03380283 0.9190705  0.00979221]\n",
      "[0.2067946  0.10813437 0.67121905 0.013852  ]\n",
      "[0.21492536 0.4407398  0.31339395 0.03094083]\n",
      "[0.12415891 0.2398908  0.6220656  0.01388469]\n",
      "[0.08656634 0.11073393 0.79247725 0.0102224 ]\n",
      "[0.51310706 0.03580071 0.4084984  0.04259384]\n",
      "[0.05212033 0.03241217 0.9062744  0.00919321]\n",
      "[0.05064825 0.05114064 0.8892805  0.00893063]\n",
      "[0.3533278  0.1029914  0.5278708  0.01581002]\n",
      "[0.04084533 0.13950142 0.80701625 0.01263696]\n",
      "[0.0452101  0.03060962 0.9153369  0.00884342]\n",
      "[0.03349897 0.02512786 0.9321302  0.00924302]\n",
      "[0.05725941 0.06703553 0.8639241  0.01178089]\n",
      "[0.10491937 0.02688463 0.85565317 0.01254283]\n",
      "[0.10023454 0.06540542 0.8249171  0.00944303]\n",
      "[0.12541972 0.04330614 0.82191724 0.00935693]\n",
      "[0.06536394 0.09823836 0.82531387 0.0110839 ]\n",
      "[0.03893861 0.03228125 0.92084986 0.00793019]\n",
      "[0.12645458 0.05654109 0.80519223 0.01181209]\n",
      "[0.13508381 0.05881858 0.7896187  0.01647894]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#Test accuracy\u001b[39;00m\n\u001b[1;32m     79\u001b[0m Dataloader_test \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39mDataLoader(Dataset_test, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m pred_labels_test, true_labels,test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataloader_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m basename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(keys)\n\u001b[1;32m     82\u001b[0m test_accuracy_list[basename]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(test_accuracy,\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[79], line 5\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, Dataloader_test)\u001b[0m\n\u001b[1;32m      3\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m []   \n\u001b[1;32m      4\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Dataloader_test):\n\u001b[1;32m      6\u001b[0m     bag_label \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m      7\u001b[0m     data, bag_label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda(), bag_label\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[35], line 45\u001b[0m, in \u001b[0;36mTSbags_random_oneslide.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     44\u001b[0m     row_list, col_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbags_list[index]\n\u001b[0;32m---> 45\u001b[0m     bag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pack_one_bag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_list[index]\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bag, label\n",
      "Cell \u001b[0;32mIn[35], line 34\u001b[0m, in \u001b[0;36mTSbags_random_oneslide._pack_one_bag\u001b[0;34m(self, row_list, col_list)\u001b[0m\n\u001b[1;32m     32\u001b[0m upperLeft_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(col_unit \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_shape\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mfactor)\n\u001b[1;32m     33\u001b[0m upperLeft_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row_unit \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_shape\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mfactor)\n\u001b[0;32m---> 34\u001b[0m patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslide_ob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupperLeft_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupperLeft_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m patch \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39marray(patch)[:,:,:\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/openslide/__init__.py:251\u001b[0m, in \u001b[0;36mOpenSlide.read_region\u001b[0;34m(self, location, level, size)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_region\u001b[39m(\u001b[38;5;28mself\u001b[39m, location, level, size):\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a PIL.Image containing the contents of the region.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    location: (x, y) tuple giving the top left pixel in the level 0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    Unlike in the C interface, the image data returned by this\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    function is not premultiplied.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     region \u001b[38;5;241m=\u001b[39m \u001b[43mlowlevel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_region\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_osr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m         region\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micc_profile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/openslide/lowlevel.py:335\u001b[0m, in \u001b[0;36mread_region\u001b[0;34m(slide, x, y, level, w, h)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m'\u001b[39m, (w, h))\n\u001b[1;32m    334\u001b[0m buf \u001b[38;5;241m=\u001b[39m (w \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m*\u001b[39m c_uint32)()\n\u001b[0;32m--> 335\u001b[0m \u001b[43m_read_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _load_image(buf, (w, h))\n",
      "File \u001b[0;32m~/osteosarcoma/venv/lib/python3.8/site-packages/openslide/lowlevel.py:230\u001b[0m, in \u001b[0;36m_check_error\u001b[0;34m(result, func, args)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# check if the library got into an error state after each library call\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_error\u001b[39m(result, func, args):\n\u001b[1;32m    231\u001b[0m     err \u001b[38;5;241m=\u001b[39m get_error(args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#step0\n",
    "# load model\n",
    "f = open(\"/cis/home/jhu104/osteosarcoma/validation and test result/test_data_dic.json\")\n",
    "test_data_dic = json.load(f)\n",
    "path = \"/cis/home/jhu104/osteosarcoma/model_vgg16tune/ml_final.pth\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = Attention_modern_multi(load_resnet())\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.to(device)\n",
    "set_bag_length =800\n",
    "test_bag_len_slide = [set_bag_length,set_bag_length,set_bag_length,set_bag_length]\n",
    "\n",
    "\n",
    "    # 'stroma':1,\n",
    "    # 'viable':2,\n",
    "    # 'necrosis':3,\n",
    "    # 'type4':4\n",
    "\n",
    "\n",
    "#step1\n",
    "#Prediction accuracy\n",
    "def prediction_accuracy(pred,true,test_bag_len_slide):\n",
    "    listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "    label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "    label_name = np.unique(true)\n",
    "    #Get classification result\n",
    "    for i in range(label_type):\n",
    "        for j in range(len(listname)):\n",
    "            class_len = int(len(pred)/label_type)\n",
    "            result = np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==j)/class_len\n",
    "            print(f\"{listname[label_name[i]]}: classification result for {listname[j]}: {result*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "#step2\n",
    "#Prediction patient accuracy\n",
    "def prediction_patient_accuracy(pred,true,test_bag_len_slide):\n",
    "    listname = ['stroma', 'viable', 'necrosis', 'cartilage']\n",
    "    label_type = int(len(pred)/test_bag_len_slide[0])\n",
    "    label_name = np.unique(true)\n",
    "    stroma_acc = []\n",
    "    viable_acc= []\n",
    "    necrosis_acc = []\n",
    "    cartilage_acc =[]\n",
    "    #Get classification result\n",
    "    for i,type in enumerate(label_name):\n",
    "        # print(f\"prediction type:{pred}\")\n",
    "        class_len = int(len(pred)/label_type)\n",
    "        result = (np.sum(np.array(pred[i*class_len:(i+1)*class_len]) ==type)/class_len)\n",
    "        if type == 0:\n",
    "            stroma_acc.append(result)\n",
    "        elif type ==1:\n",
    "            viable_acc.append(result)\n",
    "        elif type ==2:\n",
    "            necrosis_acc.append(result)\n",
    "        elif type ==3:\n",
    "            cartilage_acc.append(result)\n",
    "    return   stroma_acc,viable_acc,necrosis_acc,cartilage_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#step3\n",
    "#Compute test accuracy\n",
    "# dict(itertools.islice(test_data_dic.items(), 2,16))\n",
    "# filtered_dict = {key: value for key, value in test_data_dic.items() if value == 33}\n",
    "patient_list = [28,32,33,34,35]\n",
    "patient_metrics = {patient_id: {'stroma': [], 'viable': [], 'necrosis': [], 'cartilage': []} for patient_id in patient_list}\n",
    "test_data_dic = dict(itertools.islice(test_data_dic.items(), 11,12))\n",
    "test_accuracy_list = {} #####Slide level accuracy\n",
    "\n",
    "for keys,patient_id in test_data_dic.items():\n",
    "    Dataset_test = create_dataset_mixbag(slides_test[keys],\n",
    "                                    tissue_masks_test[keys], label_masks_test[keys],\n",
    "                                    test_bag_len_slide, level, patch_shape,length_bag_mean = 10)\n",
    "\n",
    "    print(f\"{patient_id}th patient: {keys}\")\n",
    "    #Test accuracy\n",
    "    Dataloader_test = data_utils.DataLoader(Dataset_test, batch_size = 1, shuffle = False)\n",
    "    pred_labels_test, true_labels,test_accuracy = test(model, Dataloader_test)\n",
    "    basename = os.path.basename(keys)\n",
    "    test_accuracy_list[basename]=round(test_accuracy,3)\n",
    "\n",
    "    #Print slide accuracy\n",
    "    print(\"test_accuracy = {:.3f}\".format(test_accuracy))\n",
    "    print(\"Classification Results\")\n",
    "    prediction_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "    stroma_acc,viable_acc,necrosis_acc,cartilage_acc=prediction_patient_accuracy(pred_labels_test,true_labels,test_bag_len_slide)\n",
    "\n",
    "   # Append the results for this key to the patient's metrics\n",
    "    if stroma_acc:\n",
    "        patient_metrics[patient_id]['stroma'].append(stroma_acc[0])\n",
    "    if viable_acc:  #\n",
    "        patient_metrics[patient_id]['viable'].append(viable_acc[0])\n",
    "    if necrosis_acc:\n",
    "        patient_metrics[patient_id]['necrosis'].append(necrosis_acc[0])\n",
    "    if cartilage_acc:  #\n",
    "        patient_metrics[patient_id]['cartilage'].append(cartilage_acc[0])\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "#Step4\n",
    "#Compute patient level accuracy\n",
    "print(\"Patient Level Accuracy\")\n",
    "for patient_id, metrics in patient_metrics.items():\n",
    "    print(\"\")\n",
    "    for metric ,values in metrics.items():\n",
    "        print(f\"{patient_id}th: {metric}%: {np.mean(np.array(values))*100:.2f}(std:{np.std(np.array(values))*100:.2f})\")\n",
    "\n",
    "#step5\n",
    "#Mean Acc and Std\n",
    "print(\"\")\n",
    "print(f\"Mean Accuracy:{np.mean(np.array(list(test_accuracy_list.values())))*100:.2f}(std:{np.std(np.array(list(test_accuracy_list.values())))*100:.2f})\")\n",
    "with open(\"/cis/home/jhu104/osteosarcoma/validation and test result/slide_accuracy\", \"w\") as f:\n",
    "    # Use json.dump to write the dictionary to the file with indentation\n",
    "    json.dump(test_accuracy_list, f, indent=4)\n",
    "\n",
    "test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}\n",
    "\n",
    "\n",
    "##each slide accuracy\n",
    "test_accuracy_list_updated={key:round(value*100,3) for key, value in test_accuracy_list.items()}\n",
    "test_accuracy_pd = pd.DataFrame(test_accuracy_list_updated.items())\n",
    "test_accuracy_pd =test_accuracy_pd.rename(columns={0:\"Patient_ID\",1:\"Test Accuracy\"})\n",
    "print(test_accuracy_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "test_data_dic1 = dict(itertools.islice(test_data_dic.items(), 11,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.44.45.ndpi': 33}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Inference Using Multiple slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSbags_apply_neighbor(data_utils.Dataset):\n",
    "    def __init__(self,slide_ob, unit, ROW, COL, level, patch_shape, transform = None):\n",
    "        self.slide_ob = slide_ob\n",
    "        self.unit = unit\n",
    "        #ROW=np.where(mask_tissue==1)[0],COL=np.where(mask_tissue==1)[1]\n",
    "        #All the pixels coordinates belong to tissue\n",
    "        self.ROW, self.COL = ROW, COL\n",
    "        self.level = level\n",
    "        self.patch_shape = patch_shape\n",
    "        self.transform = transform\n",
    "    def pack_one_bag(self, row, col):\n",
    "        factor = self.slide_ob.level_downsamples[self.level]\n",
    "        #Find the upperleft coordinate for read_region in openslide\n",
    "        upperLeft_bag_x = int(col * self.unit+self.unit/2-(self.patch_shape)/2*factor)\n",
    "        upperLeft_bag_y = int(row * self.unit+self.unit/2-(self.patch_shape)/2*factor)\n",
    "        patch = Image.fromarray(np.array(self.slide_ob.read_region((upperLeft_bag_x,upperLeft_bag_y),self.level,(self.patch_shape,self.patch_shape)))[:,:,:3])\n",
    "        if self.transform is not None:\n",
    "            patch = self.transform(patch)\n",
    "        #Stack patches into one bag, in this case, it is singleton bag(One patch)\n",
    "        bag = np.stack([patch], axis=0)\n",
    "        return bag\n",
    "    def __len__(self):\n",
    "        return len(self.ROW)\n",
    "    def __getitem__(self,idx):\n",
    "        #Coordinate of one pixel belong to tissue\n",
    "        row_center_bag, col_center_bag = self.ROW[idx], self.COL[idx]\n",
    "        bag = self.pack_one_bag(row_center_bag, col_center_bag)\n",
    "        return bag, row_center_bag, col_center_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(slide_ob, model, mask_tissue, level, patch_shape):\n",
    "    \"\"\"\n",
    "    Inference\n",
    "    - Input\n",
    "        slide_ob\n",
    "        model: trained model\n",
    "        unit: downsampled scale of heatmaps (compared with x40 magnification)\n",
    "        level: resolution of patches (level of WSI)\n",
    "        patch_shape: size of patch at corresponding level\n",
    "    -Return\n",
    "        heatmap_stroma\n",
    "        heatmap_necrosis\n",
    "        heatmap_viable\n",
    "    \"\"\"\n",
    "    # dataset\n",
    "    unit = int(slide_ob.dimensions[0]/mask_tissue.shape[1])\n",
    "    apply_set = TSbags_apply_neighbor(slide_ob = slide_ob,\n",
    "                                  unit=unit,\n",
    "                                  ROW=np.where(mask_tissue==1)[0],\n",
    "                                  COL=np.where(mask_tissue==1)[1],\n",
    "                                  level = level,\n",
    "                                  patch_shape = patch_shape,\n",
    "                                  transform = transforms.Compose([transforms.Resize(224),transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "    apply_loader = data_utils.DataLoader(apply_set, batch_size = 1, shuffle = False)\n",
    "    # inference\n",
    "    # initialize heatmaps\n",
    "    channels = ['stroma','viable','necrosis',\"type4\"]\n",
    "    heatmap_stroma = np.zeros_like(mask_tissue,dtype=float)\n",
    "    heatmap_necrosis = np.zeros_like(mask_tissue,dtype=float)\n",
    "    heatmap_viable = np.zeros_like(mask_tissue,dtype=float)\n",
    "    heatmap_type4 = np.zeros_like(mask_tissue,dtype=float)\n",
    "    heatmap_stroma[:] = np.nan\n",
    "    heatmap_necrosis[:] = np.nan\n",
    "    heatmap_viable[:] = np.nan\n",
    "    heatmap_type4[:] = np.nan\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device=device)\n",
    "    pred_list =[]\n",
    "    for batch_idx, (bag, row_center_bag, col_center_bag) in enumerate(apply_loader):\n",
    "        bag = bag.to(device=device, dtype=torch.float)\n",
    "        bag = Variable(bag,requires_grad=False)\n",
    "        #Predictions\n",
    "        Y_prob, _ = model.forward(bag)\n",
    "        Y_prob = Y_prob.cpu().data.numpy()[0]\n",
    "        del bag\n",
    "        #Pixel Coordinates belongs to tissue\n",
    "        row_center_bag = row_center_bag.cpu().data.numpy()[0]\n",
    "        col_center_bag = col_center_bag.cpu().data.numpy()[0]\n",
    "        pred_list.append(np.argmax(Y_prob))\n",
    "        if batch_idx%50 == 0:\n",
    "            print(batch_idx,'/',len(apply_set),Y_prob)\n",
    "            print(batch_idx,'/',len(apply_set),channels[np.argmax(Y_prob)])\n",
    "        #Assign probability to each coordinate in the heatmap\n",
    "        heatmap_stroma[row_center_bag,col_center_bag] = Y_prob[0]\n",
    "        heatmap_viable[row_center_bag,col_center_bag] = Y_prob[1]\n",
    "        heatmap_necrosis[row_center_bag,col_center_bag] = Y_prob[2]\n",
    "        heatmap_type4[row_center_bag,col_center_bag] = Y_prob[3]\n",
    "    return heatmap_stroma, heatmap_necrosis, heatmap_viable,heatmap_type4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_resnet(slide_ob, model, mask_tissue, level, patch_shape):\n",
    "    \"\"\"\n",
    "    Inference\n",
    "    - Input\n",
    "        slide_ob\n",
    "        model: trained model\n",
    "        level: resolution of patches (level of WSI)\n",
    "        patch_shape: size of patch at corresponding level\n",
    "    - Return\n",
    "        heatmap_stroma\n",
    "        heatmap_necrosis\n",
    "        heatmap_viable\n",
    "        heatmap_type4\n",
    "    \"\"\"\n",
    "    # dataset\n",
    "    unit = int(slide_ob.dimensions[0] / mask_tissue.shape[1])\n",
    "    apply_set = TSbags_apply_neighbor(slide_ob=slide_ob,\n",
    "                                      unit=unit,\n",
    "                                      ROW=np.where(mask_tissue == 1)[0],\n",
    "                                      COL=np.where(mask_tissue == 1)[1],\n",
    "                                      level=level,\n",
    "                                      patch_shape=patch_shape,\n",
    "                                      transform=transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                                         std=[0.229, 0.224, 0.225])]))\n",
    "    apply_loader = data_utils.DataLoader(apply_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Initialize heatmaps\n",
    "    heatmap_stroma = np.zeros_like(mask_tissue, dtype=int)  # Changed dtype to int for binary values\n",
    "    heatmap_necrosis = np.zeros_like(mask_tissue, dtype=int)\n",
    "    heatmap_viable = np.zeros_like(mask_tissue, dtype=int)\n",
    "    heatmap_type4 = np.zeros_like(mask_tissue, dtype=int)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device=device)\n",
    "    for batch_idx, (bag, row_center_bag, col_center_bag) in enumerate(apply_loader):\n",
    "        bag = bag.to(device=device, dtype=torch.float)\n",
    "        bag = Variable(bag, requires_grad=False)\n",
    "\n",
    "        # Predictions\n",
    "        Y_prob, _ = model.forward(bag)\n",
    "        Y_hat = torch.argmax(Y_prob[0])\n",
    "        #Calculate the classification accuracy\n",
    "        Y_prob = Y_hat.cpu().data.numpy()[0]\n",
    "        predicted_class = np.argmax(Y_prob)\n",
    "\n",
    "        # Pixel Coordinates belongs to tissue\n",
    "        row_center_bag = row_center_bag.cpu().data.numpy()[0]\n",
    "        col_center_bag = col_center_bag.cpu().data.numpy()[0]\n",
    "\n",
    "        if predicted_class == 0:\n",
    "            heatmap_stroma[row_center_bag, col_center_bag] = 1\n",
    "        elif predicted_class == 1:\n",
    "            heatmap_viable[row_center_bag, col_center_bag] = 1\n",
    "        elif predicted_class == 2:\n",
    "            heatmap_necrosis[row_center_bag, col_center_bag] = 1\n",
    "        elif predicted_class == 3:\n",
    "            heatmap_type4[row_center_bag, col_center_bag] = 1\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"{batch_idx}/{len(apply_set)}, Class: {predicted_class}, Probabilities: {Y_prob}\")\n",
    "\n",
    "    return heatmap_stroma, heatmap_necrosis, heatmap_viable, heatmap_type4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /cis/home/jhu104/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 123368 [0.4799236  0.19240761 0.30688462 0.02078411]\n",
      "0 / 123368 stroma\n",
      "50 / 123368 [0.474007   0.18526672 0.3209402  0.01978616]\n",
      "50 / 123368 stroma\n",
      "100 / 123368 [0.4031451  0.20948234 0.3673894  0.01998315]\n",
      "100 / 123368 stroma\n",
      "150 / 123368 [0.43941522 0.20155603 0.33931628 0.01971244]\n",
      "150 / 123368 stroma\n",
      "200 / 123368 [0.4456135  0.20742181 0.32669964 0.02026509]\n",
      "200 / 123368 stroma\n",
      "250 / 123368 [0.45735365 0.2089174  0.31368324 0.02004566]\n",
      "250 / 123368 stroma\n",
      "300 / 123368 [0.38705415 0.20233546 0.39124715 0.01936321]\n",
      "300 / 123368 necrosis\n",
      "350 / 123368 [0.4260824  0.22100706 0.33202568 0.02088484]\n",
      "350 / 123368 stroma\n",
      "400 / 123368 [0.4458609  0.22940235 0.30328938 0.02144735]\n",
      "400 / 123368 stroma\n",
      "450 / 123368 [0.44772342 0.2080385  0.3233818  0.02085629]\n",
      "450 / 123368 stroma\n",
      "500 / 123368 [0.37183872 0.22536704 0.38313076 0.01966348]\n",
      "500 / 123368 necrosis\n",
      "550 / 123368 [0.36924094 0.21379504 0.39718983 0.01977426]\n",
      "550 / 123368 necrosis\n",
      "600 / 123368 [0.37901872 0.20500341 0.3960944  0.01988349]\n",
      "600 / 123368 necrosis\n",
      "650 / 123368 [0.37415215 0.23604217 0.36948344 0.02032219]\n",
      "650 / 123368 stroma\n",
      "700 / 123368 [0.3682472  0.21293516 0.39843446 0.02038313]\n",
      "700 / 123368 necrosis\n",
      "750 / 123368 [0.4182155  0.20844012 0.35265797 0.02068639]\n",
      "750 / 123368 stroma\n",
      "800 / 123368 [0.4027324  0.23658088 0.3394938  0.0211929 ]\n",
      "800 / 123368 stroma\n",
      "850 / 123368 [0.5108329  0.20372984 0.25951436 0.02592285]\n",
      "850 / 123368 stroma\n",
      "900 / 123368 [0.5022716  0.19361827 0.27855158 0.0255586 ]\n",
      "900 / 123368 stroma\n",
      "950 / 123368 [0.42044812 0.18299042 0.37317798 0.0233835 ]\n",
      "950 / 123368 stroma\n",
      "1000 / 123368 [0.43128553 0.1899766  0.35698202 0.02175587]\n",
      "1000 / 123368 stroma\n",
      "1050 / 123368 [0.4108804  0.19462349 0.37223265 0.02226347]\n",
      "1050 / 123368 stroma\n",
      "1100 / 123368 [0.46957585 0.17135541 0.334367   0.02470171]\n",
      "1100 / 123368 stroma\n",
      "1150 / 123368 [0.41275394 0.18848628 0.37685934 0.02190046]\n",
      "1150 / 123368 stroma\n",
      "1200 / 123368 [0.38098967 0.26567364 0.33242923 0.0209074 ]\n",
      "1200 / 123368 stroma\n",
      "1250 / 123368 [0.4657672  0.20798092 0.30355138 0.02270055]\n",
      "1250 / 123368 stroma\n",
      "1300 / 123368 [0.407195   0.22756201 0.34216484 0.02307817]\n",
      "1300 / 123368 stroma\n",
      "1350 / 123368 [0.4554208  0.2039051  0.31723484 0.02343925]\n",
      "1350 / 123368 stroma\n",
      "1400 / 123368 [0.46302372 0.19422223 0.3194241  0.02332995]\n",
      "1400 / 123368 stroma\n",
      "1450 / 123368 [0.5433639  0.17417565 0.2588251  0.02363526]\n",
      "1450 / 123368 stroma\n",
      "1500 / 123368 [0.49400505 0.21678594 0.26399574 0.02521325]\n",
      "1500 / 123368 stroma\n",
      "1550 / 123368 [0.43945992 0.18008503 0.35680997 0.02364509]\n",
      "1550 / 123368 stroma\n",
      "1600 / 123368 [0.5278359  0.20070523 0.24577455 0.02568432]\n",
      "1600 / 123368 stroma\n",
      "1650 / 123368 [0.43198475 0.21290337 0.33425677 0.0208551 ]\n",
      "1650 / 123368 stroma\n",
      "1700 / 123368 [0.45833728 0.15514965 0.36144102 0.02507198]\n",
      "1700 / 123368 stroma\n",
      "1750 / 123368 [0.42459118 0.18434717 0.3661067  0.02495496]\n",
      "1750 / 123368 stroma\n",
      "1800 / 123368 [0.44467986 0.2224742  0.30868545 0.02416045]\n",
      "1800 / 123368 stroma\n",
      "1850 / 123368 [0.46720126 0.20902853 0.29724196 0.02652833]\n",
      "1850 / 123368 stroma\n",
      "1900 / 123368 [0.47315016 0.20056215 0.30117    0.02511767]\n",
      "1900 / 123368 stroma\n",
      "1950 / 123368 [0.46833947 0.18953288 0.31837893 0.02374879]\n",
      "1950 / 123368 stroma\n",
      "2000 / 123368 [0.48796612 0.21882951 0.2686453  0.02455903]\n",
      "2000 / 123368 stroma\n",
      "2050 / 123368 [0.42392635 0.23805557 0.3155693  0.02244876]\n",
      "2050 / 123368 stroma\n"
     ]
    }
   ],
   "source": [
    "number =8\n",
    "# slide = validation_data[5]\n",
    "path = \"/cis/home/jhu104/osteosarcoma/model_vgg16tune/ml_450_epoch.pth\"\n",
    "device = torch.device(\"cuda:4\")\n",
    "model = Attention_modern_multi(load_resnet())\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.to(device)\n",
    "heatmap_stroma, heatmap_necrosis, heatmap_viable,heatmap_type4 = inference(slides_test[test_data[-1]], model, tissue_masks_test[test_data[-1]], level, patch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cis/home/jhu104/jhu101/OTS-23-17323 - 2023-06-16 13.44.45.ndpi'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_stack = np.stack((heatmap_necrosis, heatmap_stroma, heatmap_viable), axis=2)\n",
    "\n",
    "# Initialize an RGB image with the same dimensions as your heatmaps\n",
    "# Assigning each category a different color for visualization\n",
    "# Here, we'll use red for necrosis, green for stroma, and blue for viable\n",
    "heatmap_rgb = np.ones((*heatmap_stack.shape[:2], 3))\n",
    "\n",
    "# Overlay the categories on the white background\n",
    "# We will set the corresponding color channels to 0 where a particular category is present\n",
    "# Necrosis in red (set green and blue channels to 0 where necrosis is present)\n",
    "heatmap_rgb[..., 1] -= heatmap_stack[..., 0]  # Subtracting from green channel\n",
    "heatmap_rgb[..., 2] -= heatmap_stack[..., 0]  # Subtracting from blue channel\n",
    "\n",
    "# Stroma in green (set red and blue channels to 0 where stroma is present)\n",
    "heatmap_rgb[..., 0] -= heatmap_stack[..., 1]  # Subtracting from red channel\n",
    "heatmap_rgb[..., 2] -= heatmap_stack[..., 1]  # Subtracting from blue channel\n",
    "\n",
    "# Viable in blue (set red and green channels to 0 where viable tissue is present)\n",
    "heatmap_rgb[..., 0] -= heatmap_stack[..., 2]  # Subtracting from red channel\n",
    "heatmap_rgb[..., 1] -= heatmap_stack[..., 2]  # Subtracting from green channel\n",
    "\n",
    "# Ensure that the values are within the valid range [0, 1]\n",
    "heatmap_rgb = np.clip(heatmap_rgb, 0, 1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(heatmap_rgb)\n",
    "plt.title('Binary Heatmap with White Background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 misclassified patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming heatmap_stroma is your prediction and ground_truth is the actual label\n",
    "ground_truth = label_masks_test[test_data[number]]\n",
    "\n",
    "# Check for places where the ground truth is 1 (stroma) but heatmap_stroma is 0 (predicted as non-stroma)\n",
    "misclassified_indices = np.where((ground_truth == 1) & (heatmap_stroma == 0))\n",
    "\n",
    "# Extract row and column indices\n",
    "misclassified_rows = misclassified_indices[0]\n",
    "misclassified_cols = misclassified_indices[1]\n",
    "\n",
    "# Print or return the misclassified coordinates\n",
    "for row, col in zip(misclassified_rows, misclassified_cols):\n",
    "    print(f\"Misclassified at Row: {row}, Column: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(tissue_masks_test[test_data[number]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def pack_one_bag(slide_ob, row, col, level, patch_shape, unit=256, transform=None):\n",
    "    factor = slide_ob.level_downsamples[level]\n",
    "    # Find the upper-left coordinate for read_region in openslide\n",
    "    upperLeft_bag_x = int(col * unit + unit / 2 - (patch_shape) / 2 * factor)\n",
    "    upperLeft_bag_y = int(row * unit + unit / 2 - (patch_shape) / 2 * factor)\n",
    "    \n",
    "    # Read the region (patch) from the slide\n",
    "    patch = Image.fromarray(np.array(slide_ob.read_region((upperLeft_bag_x, upperLeft_bag_y), level, (patch_shape, patch_shape)))[:, :, :3])\n",
    "    \n",
    "    # Apply any transformations if they exist\n",
    "    if transform is not None:\n",
    "        patch = transform(patch)\n",
    "    \n",
    "    # Return the transformed patch\n",
    "    return patch\n",
    "\n",
    "# Define the slide, level, and patch_shape as per your context\n",
    "slide_ob = slides_test[test_data[number]]  # The slide object\n",
    "level = 0  # or your specific level\n",
    "patch_shape = 256  # or your specific patch size\n",
    "\n",
    "for row, col in zip(misclassified_rows, misclassified_cols):\n",
    "    if row>150 and row<250 and col>127 and col<180:\n",
    "    # Extract the patch using your method\n",
    "    # row, col = 127, 246  # Example coordinates\n",
    "        patch = pack_one_bag(slide_ob, row, col, level, patch_shape)\n",
    "        \n",
    "        if isinstance(patch, torch.Tensor):\n",
    "            patch = patch.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Display the patch\n",
    "        plt.imshow(patch)\n",
    "        plt.title(f\"Misclassified stroma patch at row {row}, col {col}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 Correctly classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming heatmap_stroma is your prediction and ground_truth is the actual label\n",
    "ground_truth = label_masks_test[test_data[number]]\n",
    "\n",
    "# Check for places where the ground truth is 1 (stroma) but heatmap_stroma is 0 (predicted as non-stroma)\n",
    "misclassified_indices = np.where((ground_truth == 1) & (heatmap_stroma == 1))\n",
    "\n",
    "# Extract row and column indices\n",
    "misclassified_rows = misclassified_indices[0]\n",
    "misclassified_cols = misclassified_indices[1]\n",
    "\n",
    "# Print or return the misclassified coordinates\n",
    "for row, col in zip(misclassified_rows, misclassified_cols):\n",
    "    print(f\"Misclassified at Row: {row}, Column: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def pack_one_bag(slide_ob, row, col, level, patch_shape, unit=256, transform=None):\n",
    "    factor = slide_ob.level_downsamples[level]\n",
    "    # Find the upper-left coordinate for read_region in openslide\n",
    "    upperLeft_bag_x = int(col * unit + unit / 2 - (patch_shape) / 2 * factor)\n",
    "    upperLeft_bag_y = int(row * unit + unit / 2 - (patch_shape) / 2 * factor)\n",
    "    \n",
    "    # Read the region (patch) from the slide\n",
    "    patch = Image.fromarray(np.array(slide_ob.read_region((upperLeft_bag_x, upperLeft_bag_y), level, (patch_shape, patch_shape)))[:, :, :3])\n",
    "    \n",
    "    # Apply any transformations if they exist\n",
    "    if transform is not None:\n",
    "        patch = transform(patch)\n",
    "    \n",
    "    # Return the transformed patch\n",
    "    return patch\n",
    "\n",
    "# Define the slide, level, and patch_shape as per your context\n",
    "slide_ob = slides_test[test_data[number]]  # The slide object\n",
    "level = 0  # or your specific level\n",
    "patch_shape = 256  # or your specific patch size\n",
    "\n",
    "for row, col in zip(misclassified_rows, misclassified_cols):\n",
    "    if row>90 and row<150 and col>200 and col<250:\n",
    "    # Extract the patch using your method\n",
    "    # row, col = 127, 246  # Example coordinates\n",
    "        patch = pack_one_bag(slide_ob, row, col, level, patch_shape)\n",
    "        \n",
    "        if isinstance(patch, torch.Tensor):\n",
    "            patch = patch.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Display the patch\n",
    "        plt.imshow(patch)\n",
    "        plt.title(f\"Misclassified stroma patch at row {row}, col {col}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ratio(heatmap, channels = ['stroma','viable','necrosis',\"type4\"]):\n",
    "    M = {}\n",
    "    mask_predicted_1 = np.zeros((heatmap.shape[0],heatmap.shape[1]))\n",
    "    mask_predicted_1[:] = np.nan\n",
    "    mask_predicted = np.argmax(heatmap,axis=2)\n",
    "    mask_predicted_1[heatmap[:,:,0]>0] = mask_predicted[heatmap[:,:,0]>0]\n",
    "    for i in range(len(channels)):\n",
    "        M[channels[i]] = np.nansum(mask_predicted_1==i)/np.sum(heatmap[:,:,i]>=0)*100\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_annotations(slide_ob, annot, unit, drawing_parameters,s=0.5,fontsize=10):\n",
    "    thumbnail = slide_ob.get_thumbnail((slide_ob.dimensions[0]//unit,slide_ob.dimensions[1]//unit))\n",
    "    f, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.imshow(thumbnail)\n",
    "    for label in drawing_parameters:     \n",
    "        for region in annot[label]['outer']:\n",
    "            x = [i[0]/unit for i in region]\n",
    "            y = [i[1]/unit for i in region]\n",
    "            if region == annot[label]['outer'][0]:\n",
    "                ax.scatter(x,y,c = drawing_parameters[label]['color'], label = drawing_parameters[label]['legend'],s=s)\n",
    "            else:\n",
    "                ax.scatter(x,y,c = drawing_parameters[label]['color'],s=s)    \n",
    "    for region in annot[label]['inner']:\n",
    "            x = [i[0]/unit for i in region]\n",
    "            y = [i[1]/unit for i in region]\n",
    "            if region == annot[label]['inner'][0]:\n",
    "                ax.scatter(x,y,c = drawing_parameters[label]['color'], label = drawing_parameters[label]['legend'],s=s)\n",
    "            else:\n",
    "                ax.scatter(x,y,c = drawing_parameters[label]['color'],s=s)   \n",
    "    ax.legend(fontsize=fontsize)\n",
    "    ax.set_axis_off()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inference\n",
    "unit = 256\n",
    "level = 2 # x10 magnification\n",
    "patch_shape = 256\n",
    "# load model\n",
    "path = \"/cis/home/jhu104/osteosarcoma/model_vgg16tune/ml_300_epoch.pth\"\n",
    "device = torch.device(\"cuda:4\")\n",
    "model = Attention_modern_multi(load_vgg16_tune())\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.to(device)\n",
    "#Go through the images\n",
    "for slide_path in test_data:\n",
    "    print(slide_path)\n",
    "    adjust_otsu= Settings_test[slide_path]['adjust_otsu']\n",
    "    slide_ob = openslide.OpenSlide(slide_path)\n",
    "    width,height = slide_ob.dimensions\n",
    "    width_downsample, height_downsample = width//unit, height//unit\n",
    "    thumbnail = slide_ob.get_thumbnail((width_downsample,width_downsample))\n",
    "    mask_tissue = generate_tissue_mask(slide_ob,unit,adjust_otsu)            \n",
    "    # Inference/cis/home/jhu104/osteosarcoma/heatmap_multiple_slides_100\n",
    "    heatmap_stroma, heatmap_necrosis, heatmap_viable,heatmap_type4 = inference(slide_ob, model, mask_tissue, level, patch_shape)\n",
    "    np.save(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_stroma.npy',heatmap_stroma)\n",
    "    np.save(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_necrosis.npy',heatmap_necrosis)\n",
    "    np.save(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_viable.npy',heatmap_viable)\n",
    "    np.save(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}heatmap_type4.npy',heatmap_type4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Visualization the WSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit =  256\n",
    "for i, slide_path in enumerate(test_data):\n",
    "    print('\\n',slide_path)\n",
    "    # read slides\n",
    "    slide_ob = openslide.OpenSlide(slide_path)\n",
    "    # read annotations\n",
    "    annots_coarse =  read_Aaron_annotations(test_label[i])\n",
    "    # read heatmaps\n",
    "    heatmap_stroma = np.load(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_stroma.npy')\n",
    "    heatmap_necrosis = np.load(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_necrosis.npy')\n",
    "    heatmap_viable = np.load(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}_heatmap_viable.npy')\n",
    "    heatmap_type4 = np.load(f'/cis/home/jhu104/osteosarcoma/heatmap_final/{os.path.basename(slide_path)}heatmap_type4.npy')\n",
    "    # show coarse annotations\n",
    "    drawing_parameters = {'stroma':{'color':'lime', 'legend':'Non-tumor'},\n",
    "                         'viable':{'color':'blue', 'legend':'Viable tumor'},\n",
    "                         'necrosis':{'color':'red', 'legend':'Necrosis'},\n",
    "                         'type4':{'color':'pink', 'legend':'type4'},}\n",
    "    show_annotations(slide_ob, annots_coarse, unit,drawing_parameters)\n",
    "    # stack heatmaps\n",
    "    heatmap_stack = np.stack((heatmap_necrosis,heatmap_stroma,heatmap_viable,heatmap_type4),axis=2)\n",
    "    heatmap_stack_show = np.zeros_like(heatmap_stack,dtype=float)\n",
    "    heatmap_stack_show[:] = 1\n",
    "    heatmap_stack_show[heatmap_stack>0]= heatmap_stack[heatmap_stack>0]\n",
    "    f, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "    plt.imshow(heatmap_stack_show[:,:,0:3])\n",
    "    ax.set_axis_off()  \n",
    "    \n",
    "\n",
    "    M = measure_ratio(heatmap_stack, channels = ['necrosis','non-tumor','viable',\"type4\"])\n",
    "    print('Necrosis/tumor: {:.3f}%'.format(100*M['necrosis']/(M['necrosis']+M['viable'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osteosarcoma_env",
   "language": "python",
   "name": "osteosarcoma_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
